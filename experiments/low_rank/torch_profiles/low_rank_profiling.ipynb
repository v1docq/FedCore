{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a7e4e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "from fedcore.algorithm.low_rank.low_rank_opt import LowRankModel\n",
    "from fedcore.architecture.utils.misc import count_params\n",
    "from fedcore.models.network_impl.decomposed_layers import IDecomposed\n",
    "from fedcore.repository.constanst_repository import SLRStrategiesEnum\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from fedcore.tools.metrics.two_model_compairing_metrics import compare_accuracy\n",
    "from fedcore.tools.dataload.small_cifar10_dataloader import get_small_cifar10_train_and_val_loaders\n",
    "from fedcore.tools.template_fedcore_models import create_low_rank_with_prune_on_0_epoch\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from fedcore.algorithm.low_rank.hooks import OnetimeRankPruner\n",
    "from fedcore.tools.ruler import PerformanceEvaluator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a08905",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "inputs = torch.randn(5, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "590f7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5736d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference        -0.52%    -599.000us       100.00%     116.213ms     116.213ms             1  \n",
      "                     aten::conv2d         4.16%       4.830ms        54.94%      63.853ms       3.193ms            20  \n",
      "                aten::convolution         0.35%     401.000us        54.85%      63.741ms       3.187ms            20  \n",
      "               aten::_convolution         0.18%     212.000us        54.50%      63.340ms       3.167ms            20  \n",
      "         aten::mkldnn_convolution        54.10%      62.876ms        54.32%      63.128ms       3.156ms            20  \n",
      "                     aten::linear         0.21%     246.000us        21.58%      25.077ms      25.077ms             1  \n",
      "                      aten::addmm        21.30%      24.759ms        21.33%      24.789ms      24.789ms             1  \n",
      "                 aten::max_pool2d         0.02%      25.000us        10.36%      12.039ms      12.039ms             1  \n",
      "    aten::max_pool2d_with_indices        10.34%      12.014ms        10.34%      12.014ms      12.014ms             1  \n",
      "                 aten::batch_norm         0.21%     244.000us         6.68%       7.760ms     388.000us            20  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 116.213ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a0c8cfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "LearningConfig(learning_strategy='from_checkpoint', peft_strategy='low_rank', criterion='cross_entropy', peft_strategy_params=LowRank(log_each=None, eval_each=None, save_each=None, epochs=0, optimizer='adam', scheduler=None, criterion='cross_entropy', custom_learning_params={}, custom_criterions={}, model_architecture=ModelArchitectureConfig(input_dim=None, output_dim=None, depth=3, custom_model_params={}), strategy='quantile', rank_prune_each=-1, compose_mode=None, non_adaptive_threshold=0.5, finetune_params=NeuralModelConfig(log_each=None, eval_each=None, save_each=None, epochs=1, optimizer='adam', scheduler=None, criterion='cross_entropy', custom_learning_params={}, custom_criterions={}, model_architecture=ModelArchitectureConfig(input_dim=None, output_dim=None, depth=3, custom_model_params={}))), learning_strategy_params=NeuralModelConfig(log_each=None, eval_each=None, save_each=None, epochs=1, optimizer='adam', scheduler=None, criterion='cross_entropy', custom_learning_params={}, custom_criterions={}, model_architecture=ModelArchitectureConfig(input_dim=None, output_dim=None, depth=3, custom_model_params={})))\n",
      "2025-11-26 02:38:51,171 - Device <cpu> is selected\n",
      "2025-11-26 02:38:51,171 - Device <cpu> is selected\n",
      "2025-11-26 02:38:51,313 - Device <cpu> is selected\n",
      "Params: 11.181642 M => 12.668856 M\n",
      "MACs: 0.296209 B => 0.000077 B\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fedcore.tools.dataload.small_cifar10_dataloader import get_small_cifar10_train_and_val_loaders\n",
    "from fedcore.tools.template_fedcore_models import create_low_rank_with_prune_on_0_epoch\n",
    "\n",
    "\n",
    "train_dataloader, val_dataloader = get_small_cifar10_train_and_val_loaders(batch_size=8, val_size=1000)\n",
    "\n",
    "TRAINED_LR, data = create_low_rank_with_prune_on_0_epoch(train_dataloader, val_dataloader, epochs=0) #TODO почему то уже даже при одной эпохе качество модели падает с 0.93 до 0.6\n",
    "TRAINED_LR.fit(input_data=data)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "558665b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_body(trained_lr: LowRankModel, bs=8, thr=0.05, mode=SLRStrategiesEnum._member_names_[0], comp=\"one_layer\", device_str=\"cpu\", compare_with_decomposed=False, n_eval=8, eval_only_model_before=False, eval_only_model_after=False):\n",
    "        \"\"\"COMPAIRING INIT NON DECOMPOSED MODEL (model_before) WITH MODEL_AFTER\n",
    "        WITH PRUNING\n",
    "        \"\"\"\n",
    "        print(f\"Running experiment bs={bs} thr={thr} mode={mode} compose={comp}\")\n",
    "        # copy model for experiment\n",
    "        trained_lr = deepcopy(trained_lr)\n",
    "        #model before - is clean Conv2d model\n",
    "        if (compare_with_decomposed):\n",
    "            #if we want to compare decomposed (conv Vh and conv S*U) & decomposed+pruned+compose_mode 1, 2, 3\n",
    "            trained_lr.model_before = deepcopy(trained_lr.model_after)\n",
    "\n",
    "        #add correct compose_mode before composition by OneTimeRankPruner\n",
    "        for name, module in trained_lr.model_after.named_modules():\n",
    "            if isinstance(module, IDecomposed): \n",
    "                 module.compose_mode = comp\n",
    "\n",
    "        #add pruner and execute\n",
    "        rank_pruner = OnetimeRankPruner()\n",
    "        rank_pruner.link_to_trainer(trained_lr.trainer)\n",
    "        rank_pruner.non_adaptive_threshold = thr\n",
    "        rank_pruner.SLR_strategy = mode\n",
    "        rank_pruner.action(None, None)\n",
    "        #after that we have compressed (by threshold) composed view. 1 2 or 3 4D tensors inside\n",
    "\n",
    "        #creating performance evaluators\n",
    "        val_loader_after = deepcopy(val_dataloader)\n",
    "        device = torch.device(device_str)\n",
    "        eval_before = PerformanceEvaluator(trained_lr.model_before, data=val_dataloader, batch_size=bs, device=device, n_batches=n_eval)\n",
    "        eval_after = PerformanceEvaluator(trained_lr.model_after, data=val_loader_after, batch_size=bs, device=device, n_batches=n_eval)\n",
    "        \n",
    "        # run evaluation\n",
    "        if (eval_only_model_before):\n",
    "            print(\"eval model_before\")\n",
    "            eval_before.warm_up_cuda()\n",
    "            thr = eval_before.throughput_eval(1)\n",
    "            return trained_lr, {}\n",
    "        if (eval_only_model_after):\n",
    "            print(\"eval model_after\")\n",
    "            eval_after.warm_up_cuda()\n",
    "            thr = eval_after.throughput_eval(1)\n",
    "            return trained_lr, {}\n",
    "        \n",
    "        print(\"eval model_before\")\n",
    "        metrics_before = eval_before.eval()\n",
    "        print(\"eval model_after\")\n",
    "        metrics_after = eval_after.eval()\n",
    "        acc_before, acc_after = compare_accuracy(trained_lr.model_before, trained_lr.model_after, val_dataloader)\n",
    "\n",
    "        # store row\n",
    "        return trained_lr, {\n",
    "            \"batch_size\": bs,\n",
    "            \"threshold\": thr,\n",
    "            \"low_rank_mode\": mode,\n",
    "            \"compose_mode\": comp,\n",
    "            \"device\": device_str,\n",
    "            # before metrics\n",
    "            \"before_latency_mean s\": metrics_before.get(\"latency\", [None])[0] if isinstance(metrics_before.get(\"latency\"), (list, tuple)) else None,\n",
    "            \"before_latency_std s\": metrics_before.get(\"latency\", [None, None])[1] if isinstance(metrics_before.get(\"latency\"), (list, tuple)) else None,\n",
    "            \"before_throughput_mean s\": metrics_before.get(\"throughput\", [None])[0] if isinstance(metrics_before.get(\"throughput\"), (list, tuple)) else None,\n",
    "            \"before_throughput_std s\": metrics_before.get(\"throughput\", [None, None])[1] if isinstance(metrics_before.get(\"throughput\"), (list, tuple)) else None,\n",
    "            \"before_model_size_mb\": metrics_before.get(\"model_size\", [None])[0] if isinstance(metrics_before.get(\"model_size\"), (list, tuple)) else None,\n",
    "            \"before_params\": count_params(trained_lr.model_before),\n",
    "            \"before_accuracy\": acc_before,\n",
    "            # after metrics\n",
    "            \"after_params\": count_params(trained_lr.model_after),\n",
    "            \"after_latency_mean s\": metrics_after.get(\"latency\", [None])[0] if isinstance(metrics_after.get(\"latency\"), (list, tuple)) else None,\n",
    "            \"after_latency_std s\": metrics_after.get(\"latency\", [None, None])[1] if isinstance(metrics_after.get(\"latency\"), (list, tuple)) else None,\n",
    "            \"after_throughput_mean s\": metrics_after.get(\"throughput\", [None])[0] if isinstance(metrics_after.get(\"throughput\"), (list, tuple)) else None,\n",
    "            \"after_throughput_std s\": metrics_after.get(\"throughput\", [None, None])[1] if isinstance(metrics_after.get(\"throughput\"), (list, tuple)) else None,\n",
    "            \"after_model_size_mb\": metrics_after.get(\"model_size\", [None])[0] if isinstance(metrics_after.get(\"model_size\"), (list, tuple)) else None,\n",
    "            \"after_accuracy\": acc_after,\n",
    "        }\n",
    "\n",
    "def full_experiment(trained_lr: LowRankModel, device_str, compare_with_decomposed=False, n_eval=8):\n",
    "    batch_sizes = [16] #16, 32]                     # можно расширить до 1..128\n",
    "    thresholds = [0.1]#[0.0001, 0.1, 0.5, 0.9]#0.1, 0.2, 0.4]\n",
    "    low_rank_modes = [SLRStrategiesEnum._member_names_[0]]\n",
    "    compose_modes = [\"one_layer\"] #[\"one_layer\", \"two_layers\", \"three_layers\"]\n",
    "\n",
    "\n",
    "    rows = []\n",
    "    all_iterations = len(batch_sizes) * len(thresholds) * len(low_rank_modes) * len(compose_modes)\n",
    "\n",
    "    # loop over parameter grid\n",
    "    i = 1\n",
    "    for bs, thr, mode, comp in itertools.product(batch_sizes, thresholds, low_rank_modes, compose_modes):\n",
    "        print(\"STEP:\", i, \"FROM\", all_iterations)\n",
    "        rows.append(experiment_body(trained_lr, bs, thr, mode, comp, device_str, compare_with_decomposed, n_eval)[1])\n",
    "        print(f\"Done device={device_str} bs={bs} thr={thr} comp={comp}\")\n",
    "        i = i + 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a62e70c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP: 1 FROM 1\n",
      "Running experiment bs=16 thr=0.1 mode=quantile compose=one_layer\n",
      "After rank pruning left only 94 % of conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.0.conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.0.conv2 layer params\n",
      "After rank pruning left only 94 % of layer1.1.conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.1.conv2 layer params\n",
      "After rank pruning left only 91 % of layer2.0.conv1 layer params\n",
      "After rank pruning left only 91 % of layer2.0.conv2 layer params\n",
      "After rank pruning left only 94 % of layer2.0.downsample.0 layer params\n",
      "After rank pruning left only 91 % of layer2.1.conv1 layer params\n",
      "After rank pruning left only 91 % of layer2.1.conv2 layer params\n",
      "After rank pruning left only 91 % of layer3.0.conv1 layer params\n",
      "After rank pruning left only 91 % of layer3.0.conv2 layer params\n",
      "After rank pruning left only 91 % of layer3.0.downsample.0 layer params\n",
      "After rank pruning left only 91 % of layer3.1.conv1 layer params\n",
      "After rank pruning left only 91 % of layer3.1.conv2 layer params\n",
      "After rank pruning left only 90 % of layer4.0.conv1 layer params\n",
      "After rank pruning left only 90 % of layer4.0.conv2 layer params\n",
      "After rank pruning left only 91 % of layer4.0.downsample.0 layer params\n",
      "After rank pruning left only 90 % of layer4.1.conv1 layer params\n",
      "After rank pruning left only 90 % of layer4.1.conv2 layer params\n",
      "After rank pruning left only 100 % of fc layer params\n",
      "eval model_before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 91.19it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 56.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval model_after\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 78.34it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 60.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done device=cpu bs=16 thr=0.1 comp=one_layer\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        experiment_rows = full_experiment(TRAINED_LR, \"cpu\", n_eval=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "779e2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        23.14%     216.353ms       100.00%     934.909ms     934.909ms             1  \n",
      "                                           aten::conv2d         1.12%      10.433ms        35.33%     330.268ms     317.565us          1040  \n",
      "                                      aten::convolution         0.75%       6.984ms        34.79%     325.270ms     312.760us          1040  \n",
      "                                     aten::_convolution         0.81%       7.569ms        33.88%     316.792ms     304.608us          1040  \n",
      "                               aten::mkldnn_convolution        26.39%     246.758ms        26.80%     250.520ms     340.380us           736  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        15.15%     141.685ms        22.62%     211.461ms       4.146ms            51  \n",
      "                                      aten::thnn_conv2d         0.49%       4.595ms         6.21%      58.049ms     190.951us           304  \n",
      "                             aten::_slow_conv2d_forward         5.99%      56.001ms         6.08%      56.864ms     187.053us           304  \n",
      "                                       aten::batch_norm         0.46%       4.286ms         5.11%      47.806ms      45.967us          1040  \n",
      "                           aten::_batch_norm_impl_index         0.88%       8.199ms         4.70%      43.946ms      42.256us          1040  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 934.909ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0290283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment bs=16 thr=0.1 mode=quantile compose=one_layer\n",
      "After rank pruning left only 94 % of conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.0.conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.0.conv2 layer params\n",
      "After rank pruning left only 94 % of layer1.1.conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.1.conv2 layer params\n",
      "After rank pruning left only 91 % of layer2.0.conv1 layer params\n",
      "After rank pruning left only 91 % of layer2.0.conv2 layer params\n",
      "After rank pruning left only 94 % of layer2.0.downsample.0 layer params\n",
      "After rank pruning left only 91 % of layer2.1.conv1 layer params\n",
      "After rank pruning left only 91 % of layer2.1.conv2 layer params\n",
      "After rank pruning left only 91 % of layer3.0.conv1 layer params\n",
      "After rank pruning left only 91 % of layer3.0.conv2 layer params\n",
      "After rank pruning left only 91 % of layer3.0.downsample.0 layer params\n",
      "After rank pruning left only 91 % of layer3.1.conv1 layer params\n",
      "After rank pruning left only 91 % of layer3.1.conv2 layer params\n",
      "After rank pruning left only 90 % of layer4.0.conv1 layer params\n",
      "After rank pruning left only 90 % of layer4.0.conv2 layer params\n",
      "After rank pruning left only 91 % of layer4.0.downsample.0 layer params\n",
      "After rank pruning left only 90 % of layer4.1.conv1 layer params\n",
      "After rank pruning left only 90 % of layer4.1.conv2 layer params\n",
      "After rank pruning left only 100 % of fc layer params\n",
      "eval model_before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 69.33it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 47.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval model_after\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 90.09it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 57.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        25.50%     249.714ms       100.00%     979.379ms     979.379ms             1  \n",
      "                                           aten::conv2d         0.77%       7.557ms        35.35%     346.252ms     332.935us          1040  \n",
      "                                      aten::convolution         0.65%       6.326ms        34.86%     341.402ms     328.271us          1040  \n",
      "                                     aten::_convolution         0.75%       7.372ms        34.02%     333.139ms     320.326us          1040  \n",
      "                               aten::mkldnn_convolution        26.29%     257.514ms        26.78%     262.247ms     356.314us           736  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        14.67%     143.707ms        21.96%     215.075ms       4.217ms            51  \n",
      "                                      aten::thnn_conv2d         0.43%       4.255ms         6.42%      62.855ms     206.760us           304  \n",
      "                             aten::_slow_conv2d_forward         6.20%      60.708ms         6.32%      61.894ms     203.599us           304  \n",
      "                                       aten::batch_norm         0.41%       3.979ms         4.91%      48.080ms      46.231us          1040  \n",
      "                           aten::_batch_norm_impl_index         0.84%       8.244ms         4.53%      44.403ms      42.695us          1040  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 979.379ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        experiment_body(TRAINED_LR, bs=16, thr=0.1, mode=SLRStrategiesEnum._member_names_[0], comp=\"one_layer\", device_str=\"cpu\", compare_with_decomposed=False, n_eval=8)\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90afce39",
   "metadata": {},
   "source": [
    "### FOR 1 LAYER COMPOSE AFTER THRESHOLDING  \n",
    "1040 = 20 convd2 layers * 52 call/layer  \n",
    "52 call/layer = 8 n_eval * 2 (latency + throughput) * 2 (model_b & model_a) + 10 * 2 (compare_accuracy)\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c48b9a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment bs=16 thr=0.1 mode=quantile compose=two_layers\n",
      "After rank pruning left only 94 % of conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.0.conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.0.conv2 layer params\n",
      "After rank pruning left only 94 % of layer1.1.conv1 layer params\n",
      "After rank pruning left only 94 % of layer1.1.conv2 layer params\n",
      "After rank pruning left only 91 % of layer2.0.conv1 layer params\n",
      "After rank pruning left only 91 % of layer2.0.conv2 layer params\n",
      "After rank pruning left only 94 % of layer2.0.downsample.0 layer params\n",
      "After rank pruning left only 91 % of layer2.1.conv1 layer params\n",
      "After rank pruning left only 91 % of layer2.1.conv2 layer params\n",
      "After rank pruning left only 91 % of layer3.0.conv1 layer params\n",
      "After rank pruning left only 91 % of layer3.0.conv2 layer params\n",
      "After rank pruning left only 91 % of layer3.0.downsample.0 layer params\n",
      "After rank pruning left only 91 % of layer3.1.conv1 layer params\n",
      "After rank pruning left only 91 % of layer3.1.conv2 layer params\n",
      "After rank pruning left only 90 % of layer4.0.conv1 layer params\n",
      "After rank pruning left only 90 % of layer4.0.conv2 layer params\n",
      "After rank pruning left only 91 % of layer4.0.downsample.0 layer params\n",
      "After rank pruning left only 90 % of layer4.1.conv1 layer params\n",
      "After rank pruning left only 90 % of layer4.1.conv2 layer params\n",
      "After rank pruning left only 100 % of fc layer params\n",
      "eval model_before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 50.42it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 36.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval model_after\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 48.24it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 28.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        28.51%     468.316ms       100.00%        1.643s        1.643s             1  \n",
      "                                           aten::conv2d         0.86%      14.111ms        32.91%     540.729ms     346.621us          1560  \n",
      "                                      aten::convolution         1.03%      16.906ms        32.31%     530.754ms     340.227us          1560  \n",
      "                                     aten::_convolution         1.15%      18.846ms        31.26%     513.618ms     329.242us          1560  \n",
      "                               aten::mkldnn_convolution        23.15%     380.406ms        23.73%     389.867ms     355.718us          1096  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        16.53%     271.651ms        22.47%     369.180ms       7.239ms            51  \n",
      "                                            aten::clone         0.86%      14.089ms         5.71%      93.796ms      46.734us          2007  \n",
      "                                            aten::copy_         4.80%      78.869ms         4.80%      78.869ms      14.562us          5416  \n",
      "                                       aten::batch_norm         0.36%       5.978ms         4.56%      74.880ms      72.000us          1040  \n",
      "                                      aten::thnn_conv2d         0.23%       3.717ms         4.45%      73.063ms     157.463us           464  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.643s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True, with_stack=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        compressed_model, rows = experiment_body(TRAINED_LR, bs=16, thr=0.1, mode=SLRStrategiesEnum._member_names_[0], comp=\"two_layers\", device_str=\"cpu\", compare_with_decomposed=False, n_eval=8)\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56770a21",
   "metadata": {},
   "source": [
    "1560 = 20 conv layers * 78  \n",
    "78 = (8 eval * 2 (thr/lat) + 10 accuracy) + (8 eval * 2 thr/lat + 10 accuracy) * 2 (_forward2) = 26 + 52 = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93d378d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                        model_inference        28.51%     468.316ms       100.00%        1.643s        1.643s             1                                                                                []  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        16.53%     271.651ms        22.47%     369.180ms       7.239ms            51                                                                                []  \n",
      "                                           aten::conv2d         0.01%     163.000us         1.39%      22.889ms     953.708us            24                           [[16, 512, 1, 1], [460, 512, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.01%     243.000us         1.38%      22.726ms     946.917us            24                   [[16, 512, 1, 1], [460, 512, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.01%     179.000us         1.38%      22.609ms     753.633us            30                            [[8, 512, 1, 1], [512, 512, 3, 3], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%     321.000us         1.37%      22.483ms     936.792us            24   [[16, 512, 1, 1], [460, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.01%     149.000us         1.37%      22.460ms     748.667us            30                            [[8, 512, 1, 1], [460, 512, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.03%     454.000us         1.37%      22.430ms     747.667us            30                    [[8, 512, 1, 1], [512, 512, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.02%     403.000us         1.36%      22.311ms     743.700us            30                    [[8, 512, 1, 1], [460, 512, 3, 3], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         1.32%      21.757ms         1.35%      22.162ms     923.417us            24                           [[16, 512, 1, 1], [460, 512, 3, 3], [], [], [], [], []]  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 1.643s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60cde4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 3, 7, 7])\n",
      "torch.Size([64, 60, 1, 1])\n",
      "---\n",
      "torch.Size([60, 64, 3, 3])\n",
      "torch.Size([64, 60, 1, 1])\n",
      "---\n",
      "torch.Size([60, 64, 3, 3])\n",
      "torch.Size([64, 60, 1, 1])\n",
      "---\n",
      "torch.Size([60, 64, 3, 3])\n",
      "torch.Size([64, 60, 1, 1])\n",
      "---\n",
      "torch.Size([60, 64, 3, 3])\n",
      "torch.Size([64, 60, 1, 1])\n",
      "---\n",
      "torch.Size([116, 64, 3, 3])\n",
      "torch.Size([128, 116, 1, 1])\n",
      "---\n",
      "torch.Size([116, 128, 3, 3])\n",
      "torch.Size([128, 116, 1, 1])\n",
      "---\n",
      "torch.Size([60, 64, 1, 1])\n",
      "torch.Size([128, 60, 1, 1])\n",
      "---\n",
      "torch.Size([116, 128, 3, 3])\n",
      "torch.Size([128, 116, 1, 1])\n",
      "---\n",
      "torch.Size([116, 128, 3, 3])\n",
      "torch.Size([128, 116, 1, 1])\n",
      "---\n",
      "torch.Size([232, 128, 3, 3])\n",
      "torch.Size([256, 232, 1, 1])\n",
      "---\n",
      "torch.Size([232, 256, 3, 3])\n",
      "torch.Size([256, 232, 1, 1])\n",
      "---\n",
      "torch.Size([116, 128, 1, 1])\n",
      "torch.Size([256, 116, 1, 1])\n",
      "---\n",
      "torch.Size([232, 256, 3, 3])\n",
      "torch.Size([256, 232, 1, 1])\n",
      "---\n",
      "torch.Size([232, 256, 3, 3])\n",
      "torch.Size([256, 232, 1, 1])\n",
      "---\n",
      "torch.Size([460, 256, 3, 3])\n",
      "torch.Size([512, 460, 1, 1])\n",
      "---\n",
      "torch.Size([460, 512, 3, 3])\n",
      "torch.Size([512, 460, 1, 1])\n",
      "---\n",
      "torch.Size([232, 256, 1, 1])\n",
      "torch.Size([512, 232, 1, 1])\n",
      "---\n",
      "torch.Size([460, 512, 3, 3])\n",
      "torch.Size([512, 460, 1, 1])\n",
      "---\n",
      "torch.Size([460, 512, 3, 3])\n",
      "torch.Size([512, 460, 1, 1])\n",
      "---\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10, 10])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for name, module in compressed_model.model_after.named_modules():\n",
    "    if isinstance(module, IDecomposed): \n",
    "        print(module.Vh.shape)\n",
    "        print(module.U.shape)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c807dc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(TRAINED_LR.model_before.named_modules())[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8d961840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old torch.Size([64, 3, 7, 7])\n",
      "new Vh torch.Size([60, 3, 7, 7])\n",
      "new U torch.Size([64, 60, 1, 1])\n",
      "old 9408 new 8820 + 3840 = 12660\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([60, 64, 3, 3])\n",
      "new U torch.Size([64, 60, 1, 1])\n",
      "old 36864 new 34560 + 3840 = 38400\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([60, 64, 3, 3])\n",
      "new U torch.Size([64, 60, 1, 1])\n",
      "old 36864 new 34560 + 3840 = 38400\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([60, 64, 3, 3])\n",
      "new U torch.Size([64, 60, 1, 1])\n",
      "old 36864 new 34560 + 3840 = 38400\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([60, 64, 3, 3])\n",
      "new U torch.Size([64, 60, 1, 1])\n",
      "old 36864 new 34560 + 3840 = 38400\n",
      "\n",
      "---\n",
      "old torch.Size([128, 64, 3, 3])\n",
      "new Vh torch.Size([116, 64, 3, 3])\n",
      "new U torch.Size([128, 116, 1, 1])\n",
      "old 73728 new 66816 + 14848 = 81664\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([116, 128, 3, 3])\n",
      "new U torch.Size([128, 116, 1, 1])\n",
      "old 147456 new 133632 + 14848 = 148480\n",
      "\n",
      "---\n",
      "old torch.Size([128, 64, 1, 1])\n",
      "new Vh torch.Size([60, 64, 1, 1])\n",
      "new U torch.Size([128, 60, 1, 1])\n",
      "old 8192 new 3840 + 7680 = 11520\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([116, 128, 3, 3])\n",
      "new U torch.Size([128, 116, 1, 1])\n",
      "old 147456 new 133632 + 14848 = 148480\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([116, 128, 3, 3])\n",
      "new U torch.Size([128, 116, 1, 1])\n",
      "old 147456 new 133632 + 14848 = 148480\n",
      "\n",
      "---\n",
      "old torch.Size([256, 128, 3, 3])\n",
      "new Vh torch.Size([232, 128, 3, 3])\n",
      "new U torch.Size([256, 232, 1, 1])\n",
      "old 294912 new 267264 + 59392 = 326656\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([232, 256, 3, 3])\n",
      "new U torch.Size([256, 232, 1, 1])\n",
      "old 589824 new 534528 + 59392 = 593920\n",
      "\n",
      "---\n",
      "old torch.Size([256, 128, 1, 1])\n",
      "new Vh torch.Size([116, 128, 1, 1])\n",
      "new U torch.Size([256, 116, 1, 1])\n",
      "old 32768 new 14848 + 29696 = 44544\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([232, 256, 3, 3])\n",
      "new U torch.Size([256, 232, 1, 1])\n",
      "old 589824 new 534528 + 59392 = 593920\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([232, 256, 3, 3])\n",
      "new U torch.Size([256, 232, 1, 1])\n",
      "old 589824 new 534528 + 59392 = 593920\n",
      "\n",
      "---\n",
      "old torch.Size([512, 256, 3, 3])\n",
      "new Vh torch.Size([460, 256, 3, 3])\n",
      "new U torch.Size([512, 460, 1, 1])\n",
      "old 1179648 new 1059840 + 235520 = 1295360\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([460, 512, 3, 3])\n",
      "new U torch.Size([512, 460, 1, 1])\n",
      "old 2359296 new 2119680 + 235520 = 2355200\n",
      "\n",
      "---\n",
      "old torch.Size([512, 256, 1, 1])\n",
      "new Vh torch.Size([232, 256, 1, 1])\n",
      "new U torch.Size([512, 232, 1, 1])\n",
      "old 131072 new 59392 + 118784 = 178176\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([460, 512, 3, 3])\n",
      "new U torch.Size([512, 460, 1, 1])\n",
      "old 2359296 new 2119680 + 235520 = 2355200\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([460, 512, 3, 3])\n",
      "new U torch.Size([512, 460, 1, 1])\n",
      "old 2359296 new 2119680 + 235520 = 2355200\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def compare_module_shapes(lowRankModel):\n",
    "    new_modules = list(lowRankModel.model_after.named_modules())\n",
    "    for i, (name, module) in enumerate(lowRankModel.model_before.named_modules()):\n",
    "        if isinstance(module, torch.nn.Conv2d): \n",
    "            print(\"old\", module.weight.shape)\n",
    "            print(\"new Vh\", new_modules[i][1].Vh.shape)\n",
    "            print(\"new U\", new_modules[i][1].U.shape)\n",
    "            print(\"old\", count_params(module), \"new\", new_modules[i][1].Vh.numel(), \"+\", new_modules[i][1].U.numel(), \"=\", count_params(new_modules[i][1]))\n",
    "            print()\n",
    "            print(\"---\")\n",
    "\n",
    "compare_module_shapes(compressed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0b42828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "9408 12660\n",
      "bn1\n",
      "128 128\n",
      "relu\n",
      "0 0\n",
      "maxpool\n",
      "0 0\n",
      "layer1.0.conv1\n",
      "36864 38400\n",
      "layer1.0.bn1\n",
      "128 128\n",
      "layer1.0.relu\n",
      "0 0\n",
      "layer1.0.conv2\n",
      "36864 38400\n",
      "layer1.0.bn2\n",
      "128 128\n",
      "layer1.1.conv1\n",
      "36864 38400\n",
      "layer1.1.bn1\n",
      "128 128\n",
      "layer1.1.relu\n",
      "0 0\n",
      "layer1.1.conv2\n",
      "36864 38400\n",
      "layer1.1.bn2\n",
      "128 128\n",
      "layer2.0.conv1\n",
      "73728 81664\n",
      "layer2.0.bn1\n",
      "256 256\n",
      "layer2.0.relu\n",
      "0 0\n",
      "layer2.0.conv2\n",
      "147456 148480\n",
      "layer2.0.bn2\n",
      "256 256\n",
      "layer2.0.downsample.0\n",
      "8192 11520\n",
      "layer2.0.downsample.1\n",
      "256 256\n",
      "layer2.1.conv1\n",
      "147456 148480\n",
      "layer2.1.bn1\n",
      "256 256\n",
      "layer2.1.relu\n",
      "0 0\n",
      "layer2.1.conv2\n",
      "147456 148480\n",
      "layer2.1.bn2\n",
      "256 256\n",
      "layer3.0.conv1\n",
      "294912 326656\n",
      "layer3.0.bn1\n",
      "512 512\n",
      "layer3.0.relu\n",
      "0 0\n",
      "layer3.0.conv2\n",
      "589824 593920\n",
      "layer3.0.bn2\n",
      "512 512\n",
      "layer3.0.downsample.0\n",
      "32768 44544\n",
      "layer3.0.downsample.1\n",
      "512 512\n",
      "layer3.1.conv1\n",
      "589824 593920\n",
      "layer3.1.bn1\n",
      "512 512\n",
      "layer3.1.relu\n",
      "0 0\n",
      "layer3.1.conv2\n",
      "589824 593920\n",
      "layer3.1.bn2\n",
      "512 512\n",
      "layer4.0.conv1\n",
      "1179648 1295360\n",
      "layer4.0.bn1\n",
      "1024 1024\n",
      "layer4.0.relu\n",
      "0 0\n",
      "layer4.0.conv2\n",
      "2359296 2355200\n",
      "layer4.0.bn2\n",
      "1024 1024\n",
      "layer4.0.downsample.0\n",
      "131072 178176\n",
      "layer4.0.downsample.1\n",
      "1024 1024\n",
      "layer4.1.conv1\n",
      "2359296 2355200\n",
      "layer4.1.bn1\n",
      "1024 1024\n",
      "layer4.1.relu\n",
      "0 0\n",
      "layer4.1.conv2\n",
      "2359296 2355200\n",
      "layer4.1.bn2\n",
      "1024 1024\n",
      "avgpool\n",
      "0 0\n",
      "fc\n",
      "5130 5230\n"
     ]
    }
   ],
   "source": [
    "def compare_all_modules_params(lowRankModel):\n",
    "    new_modules = list(lowRankModel.model_after.named_modules())\n",
    "    for i, (name, module) in enumerate(lowRankModel.model_before.named_modules()):\n",
    "        if (len(list(module.children())) == 0):\n",
    "            print(name)\n",
    "            print(count_params(module), count_params(new_modules[i][1]))\n",
    "\n",
    "compare_all_modules_params(compressed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11c0a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                        model_inference        59.61%        2.748s       100.00%        4.610s        4.610s             1                                                                                []  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         8.65%     398.852ms        12.11%     558.301ms      10.947ms            51                                                                                []  \n",
      "                                            aten::clone         0.01%     434.000us         2.36%     108.578ms      18.096ms             6                                                            [[512, 512, 3, 3], []]  \n",
      "                                            aten::copy_         2.33%     107.422ms         2.33%     107.422ms      17.904ms             6                                          [[512, 512, 3, 3], [512, 512, 3, 3], []]  \n",
      "                                            aten::clone         0.30%      13.843ms         0.80%      37.049ms      25.446us          1456                                                                 [[3, 32, 32], []]  \n",
      "                                         aten::quantile         0.19%       8.943ms         0.79%      36.439ms       6.073ms             6                                                            [[64], [], [], [], []]  \n",
      "                                            aten::clone         0.00%     122.000us         0.71%      32.633ms       5.439ms             6                                                            [[256, 256, 3, 3], []]  \n",
      "                                    aten::empty_strided         0.69%      31.613ms         0.69%      31.613ms       9.647us          3277                                                          [[], [], [], [], [], []]  \n",
      "                                            aten::copy_         0.67%      31.089ms         0.67%      31.089ms       5.181ms             6                                          [[256, 256, 3, 3], [256, 256, 3, 3], []]  \n",
      "                                           aten::conv2d         0.04%       1.693ms         0.63%      28.844ms       3.606ms             8                               [[1, 3, 32, 32], [64, 3, 7, 7], [], [], [], [], []]  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 4.610s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee21118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment bs=16 thr=0.2 mode=quantile compose=two_layers\n",
      "After rank pruning left only 81 % of conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.0.conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer1.1.conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.1.conv2 layer params\n",
      "After rank pruning left only 81 % of layer2.0.conv1 layer params\n",
      "After rank pruning left only 81 % of layer2.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer2.0.downsample.0 layer params\n",
      "After rank pruning left only 81 % of layer2.1.conv1 layer params\n",
      "After rank pruning left only 81 % of layer2.1.conv2 layer params\n",
      "After rank pruning left only 80 % of layer3.0.conv1 layer params\n",
      "After rank pruning left only 80 % of layer3.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer3.0.downsample.0 layer params\n",
      "After rank pruning left only 80 % of layer3.1.conv1 layer params\n",
      "After rank pruning left only 80 % of layer3.1.conv2 layer params\n",
      "After rank pruning left only 80 % of layer4.0.conv1 layer params\n",
      "After rank pruning left only 80 % of layer4.0.conv2 layer params\n",
      "After rank pruning left only 80 % of layer4.0.downsample.0 layer params\n",
      "After rank pruning left only 80 % of layer4.1.conv1 layer params\n",
      "After rank pruning left only 80 % of layer4.1.conv2 layer params\n",
      "After rank pruning left only 80 % of fc layer params\n",
      "eval model_before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 60.84it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 46.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval model_after\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "latency eval samples: 100%|██████████| 8/8 [00:00<00:00, 58.75it/s]\n",
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 41.73batch/s]\n"
     ]
    }
   ],
   "source": [
    "#with_flops=True\n",
    "with profile(activities=[ProfilerActivity.CPU], \n",
    "             #with_stack=True, \n",
    "             record_shapes=True,\n",
    "             experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True),\n",
    "             ) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        ret_model, rows = experiment_body(TRAINED_LR, bs=16, thr=0.2, mode=SLRStrategiesEnum._member_names_[0], comp=\"two_layers\", device_str=\"cpu\", compare_with_decomposed=False, n_eval=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8349b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11181642\n",
      "10179510\n"
     ]
    }
   ],
   "source": [
    "print(count_params(ret_model.model_before))\n",
    "print(count_params(ret_model.model_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1c64ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old torch.Size([64, 3, 7, 7])\n",
      "new Vh torch.Size([52, 3, 7, 7])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 9408 new 10972\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 33280\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 33280\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 33280\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 33280\n",
      "\n",
      "---\n",
      "old torch.Size([128, 64, 3, 3])\n",
      "new Vh torch.Size([104, 64, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 73728 new 73216\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([104, 128, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 147456 new 133120\n",
      "\n",
      "---\n",
      "old torch.Size([128, 64, 1, 1])\n",
      "new Vh torch.Size([52, 64, 1, 1])\n",
      "new U torch.Size([128, 52, 1, 1])\n",
      "old 8192 new 9984\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([104, 128, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 147456 new 133120\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([104, 128, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 147456 new 133120\n",
      "\n",
      "---\n",
      "old torch.Size([256, 128, 3, 3])\n",
      "new Vh torch.Size([204, 128, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 294912 new 287232\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([204, 256, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 589824 new 522240\n",
      "\n",
      "---\n",
      "old torch.Size([256, 128, 1, 1])\n",
      "new Vh torch.Size([104, 128, 1, 1])\n",
      "new U torch.Size([256, 104, 1, 1])\n",
      "old 32768 new 39936\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([204, 256, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 589824 new 522240\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([204, 256, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 589824 new 522240\n",
      "\n",
      "---\n",
      "old torch.Size([512, 256, 3, 3])\n",
      "new Vh torch.Size([412, 256, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 1179648 new 1160192\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([412, 512, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 2359296 new 2109440\n",
      "\n",
      "---\n",
      "old torch.Size([512, 256, 1, 1])\n",
      "new Vh torch.Size([204, 256, 1, 1])\n",
      "new U torch.Size([512, 204, 1, 1])\n",
      "old 131072 new 156672\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([412, 512, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 2359296 new 2109440\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([412, 512, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 2359296 new 2109440\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "compare_module_shapes(ret_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e21db135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prof.export_stacks(\"two_layers_stacktrace\") # !!! WARN doesnt supporting anymore\n",
    "prof.export_chrome_trace(\"two_layer_profile_thr_02.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "034d8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        28.51%     468.316ms       100.00%        1.643s        1.643s             1  \n",
      "                                           aten::conv2d         0.86%      14.111ms        32.91%     540.729ms     346.621us          1560  \n",
      "                                      aten::convolution         1.03%      16.906ms        32.31%     530.754ms     340.227us          1560  \n",
      "                                     aten::_convolution         1.15%      18.846ms        31.26%     513.618ms     329.242us          1560  \n",
      "                               aten::mkldnn_convolution        23.15%     380.406ms        23.73%     389.867ms     355.718us          1096  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        16.53%     271.651ms        22.47%     369.180ms       7.239ms            51  \n",
      "                                            aten::clone         0.86%      14.089ms         5.71%      93.796ms      46.734us          2007  \n",
      "                                            aten::copy_         4.80%      78.869ms         4.80%      78.869ms      14.562us          5416  \n",
      "                                       aten::batch_norm         0.36%       5.978ms         4.56%      74.880ms      72.000us          1040  \n",
      "                                      aten::thnn_conv2d         0.23%       3.717ms         4.45%      73.063ms     157.463us           464  \n",
      "                             aten::_slow_conv2d_forward         4.15%      68.156ms         4.32%      70.927ms     152.860us           464  \n",
      "                           aten::_batch_norm_impl_index         0.74%      12.142ms         4.21%      69.188ms      66.527us          1040  \n",
      "                                aten::native_batch_norm         2.91%      47.835ms         3.42%      56.148ms      53.988us          1040  \n",
      "                                       aten::contiguous         0.25%       4.052ms         2.71%      44.479ms      40.732us          1092  \n",
      "                                           aten::matmul         0.02%     283.000us         2.14%      35.208ms     749.106us            47  \n",
      "                                               aten::mm         2.13%      34.940ms         2.13%      34.943ms     743.468us            47  \n",
      "                                               aten::to         0.37%       6.113ms         1.63%      26.737ms       5.367us          4982  \n",
      "                                            aten::relu_         0.49%       7.981ms         1.50%      24.587ms      27.813us           884  \n",
      "                                       aten::max_pool2d         0.02%     403.000us         1.42%      23.289ms     447.865us            52  \n",
      "                          aten::max_pool2d_with_indices         1.39%      22.886ms         1.39%      22.886ms     440.115us            52  \n",
      "                                         aten::_to_copy         0.86%      14.150ms         1.34%      21.969ms       9.219us          2383  \n",
      "                                       aten::clamp_min_         1.02%      16.747ms         1.02%      16.747ms      18.945us           884  \n",
      "                                            aten::empty         0.97%      15.980ms         0.97%      15.980ms       1.375us         11625  \n",
      "                                              aten::div         0.57%       9.439ms         0.94%      15.443ms      21.213us           728  \n",
      "                                       aten::empty_like         0.45%       7.444ms         0.83%      13.561ms       6.299us          2153  \n",
      "                                               aten::eq         0.34%       5.590ms         0.77%      12.606ms      17.316us           728  \n",
      "                                            aten::index         0.71%      11.637ms         0.72%      11.869ms     188.397us            63  \n",
      "                                         aten::quantile         0.14%       2.260ms         0.61%      10.065ms     479.286us            21  \n",
      "                                              aten::any         0.41%       6.754ms         0.60%       9.913ms      13.235us           749  \n",
      "                                             aten::add_         0.52%       8.573ms         0.52%       8.573ms      20.608us           416  \n",
      "                                             aten::view         0.41%       6.690ms         0.41%       6.690ms       1.982us          3376  \n",
      "                                           aten::linear         0.04%     590.000us         0.39%       6.447ms      82.654us            78  \n",
      "                                          aten::permute         0.33%       5.464ms         0.39%       6.423ms       8.363us           768  \n",
      "                              aten::adaptive_avg_pool2d         0.02%     396.000us         0.37%       5.999ms     115.365us            52  \n",
      "                                             aten::mean         0.05%     838.000us         0.35%       5.698ms     109.577us            52  \n",
      "                                             aten::div_         0.23%       3.806ms         0.32%       5.320ms       6.794us           783  \n",
      "                                    aten::empty_strided         0.31%       5.040ms         0.31%       5.040ms       1.538us          3277  \n",
      "                                          aten::resize_         0.29%       4.757ms         0.29%       4.757ms       2.969us          1602  \n",
      "                                       aten::is_nonzero         0.10%       1.714ms         0.24%       4.015ms       5.515us           728  \n",
      "                                             aten::sub_         0.23%       3.825ms         0.23%       3.825ms       5.254us           728  \n",
      "                                             aten::sort         0.13%       2.160ms         0.22%       3.669ms      87.357us            42  \n",
      "                                            aten::stack         0.05%     762.000us         0.19%       3.116ms      61.098us            51  \n",
      "                                            aten::addmm         0.14%       2.240ms         0.17%       2.842ms      54.654us            52  \n",
      "                                             aten::item         0.13%       2.100ms         0.16%       2.588ms       3.414us           758  \n",
      "                                              aten::sum         0.12%       1.941ms         0.15%       2.505ms      34.315us            73  \n",
      "                                      aten::as_strided_         0.14%       2.316ms         0.14%       2.316ms       4.938us           469  \n",
      "                                              aten::cat         0.10%       1.689ms         0.14%       2.293ms      44.961us            51  \n",
      "                                          aten::view_as         0.11%       1.762ms         0.13%       2.161ms       2.885us           749  \n",
      "                                             aten::diag         0.02%     313.000us         0.12%       1.949ms      92.810us            21  \n",
      "                                           aten::detach         0.05%     892.000us         0.11%       1.793ms       3.448us           520  \n",
      "                                       aten::as_strided         0.10%       1.686ms         0.10%       1.686ms       0.975us          1729  \n",
      "                                       aten::diag_embed         0.03%     537.000us         0.10%       1.659ms      79.000us            21  \n",
      "                                           aten::arange         0.06%     979.000us         0.10%       1.600ms      19.048us            84  \n",
      "                                                aten::t         0.04%     596.000us         0.07%       1.170ms      15.000us            78  \n",
      "                                             aten::set_         0.07%       1.139ms         0.07%       1.139ms       2.296us           496  \n",
      "                                          aten::flatten         0.02%     323.000us         0.06%     981.000us      13.438us            73  \n",
      "                                                 detach         0.06%     979.000us         0.06%     979.000us       2.719us           360  \n",
      "                                            aten::slice         0.05%     828.000us         0.06%     913.000us       8.864us           103  \n",
      "                                            aten::zeros         0.01%     194.000us         0.05%     783.000us      37.286us            21  \n",
      "                                            aten::fill_         0.05%     752.000us         0.05%     752.000us       6.065us           124  \n",
      "                                               aten::ge         0.02%     344.000us         0.05%     742.000us      35.333us            21  \n",
      "                                          aten::reshape         0.03%     481.000us         0.04%     701.000us       6.806us           103  \n",
      "                                           aten::narrow         0.02%     340.000us         0.04%     604.000us      15.100us            40  \n",
      "                                           aten::argmax         0.04%     592.000us         0.04%     599.000us      29.950us            20  \n",
      "                                           aten::select         0.03%     551.000us         0.04%     588.000us      10.500us            56  \n",
      "                                        aten::transpose         0.02%     402.000us         0.03%     570.000us       7.308us            78  \n",
      "                                      aten::masked_fill         0.01%     205.000us         0.03%     541.000us      25.762us            21  \n",
      "                              aten::_local_scalar_dense         0.03%     539.000us         0.03%     539.000us       0.711us           758  \n",
      "                                              aten::all         0.03%     425.000us         0.03%     538.000us      25.619us            21  \n",
      "                                        aten::new_empty         0.02%     401.000us         0.03%     512.000us       3.631us           141  \n",
      "                                       aten::lift_fresh         0.03%     499.000us         0.03%     499.000us       0.223us          2235  \n",
      "                                              aten::mul         0.02%     311.000us         0.03%     497.000us      23.667us            21  \n",
      "                                            aten::zero_         0.01%      92.000us         0.03%     489.000us      23.286us            21  \n",
      "                                           aten::expand         0.02%     356.000us         0.02%     407.000us       5.575us            73  \n",
      "                                              aten::sub         0.01%     211.000us         0.02%     376.000us      17.905us            21  \n",
      "                                          aten::squeeze         0.02%     361.000us         0.02%     366.000us      18.300us            20  \n",
      "                                               aten::le         0.01%     176.000us         0.02%     338.000us      16.095us            21  \n",
      "                                           aten::gather         0.02%     326.000us         0.02%     326.000us       7.762us            42  \n",
      "                                aten::broadcast_tensors         0.01%     126.000us         0.02%     294.000us      14.000us            21  \n",
      "                                            aten::lerp_         0.02%     269.000us         0.02%     269.000us      12.810us            21  \n",
      "                                          aten::detach_         0.01%     147.000us         0.02%     261.000us       5.118us            51  \n",
      "                                         aten::squeeze_         0.01%     176.000us         0.02%     260.000us      12.381us            21  \n",
      "                                         aten::new_ones         0.01%     166.000us         0.01%     243.000us      11.571us            21  \n",
      "                                          aten::random_         0.01%     231.000us         0.01%     231.000us      25.667us             9  \n",
      "                                            aten::isnan         0.00%      81.000us         0.01%     222.000us      10.571us            21  \n",
      "                                     aten::logical_and_         0.01%     113.000us         0.01%     204.000us       9.714us            21  \n",
      "                                   aten::_reshape_alias         0.01%     203.000us         0.01%     203.000us       5.075us            40  \n",
      "                                            aten::equal         0.01%     154.000us         0.01%     155.000us       7.381us            21  \n",
      "                                         aten::diagonal         0.01%     121.000us         0.01%     155.000us       7.381us            21  \n",
      "                                            aten::ceil_         0.01%     148.000us         0.01%     148.000us       7.048us            21  \n",
      "                                               aten::gt         0.01%     147.000us         0.01%     147.000us       7.000us            21  \n",
      "                                               aten::ne         0.01%     145.000us         0.01%     145.000us       6.905us            21  \n",
      "                                                detach_         0.01%     137.000us         0.01%     137.000us       2.686us            51  \n",
      "                                        aten::unsqueeze         0.01%     112.000us         0.01%     122.000us       7.625us            16  \n",
      "                                    aten::scalar_tensor         0.01%     105.000us         0.01%     105.000us       5.000us            21  \n",
      "                                      aten::logical_and         0.01%      91.000us         0.01%      91.000us       4.333us            21  \n",
      "                                     aten::masked_fill_         0.00%      71.000us         0.00%      71.000us       3.381us            21  \n",
      "                                     aten::resolve_conj         0.00%       5.000us         0.00%       5.000us       0.020us           249  \n",
      "                                     aten::is_same_size         0.00%       1.000us         0.00%       1.000us       0.048us            21  \n",
      "                aten::_has_compatible_shallow_copy_type         0.00%       1.000us         0.00%       1.000us       0.003us           290  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.643s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a65358ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(<ProfilerAction.NONE: 0>, <ProfilerAction.NONE: 0>): [],\n",
       " (<ProfilerAction.NONE: 0>,\n",
       "  <ProfilerAction.WARMUP: 1>): [<bound method _KinetoProfile.prepare_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.NONE: 0>,\n",
       "  <ProfilerAction.RECORD: 2>): [<bound method _KinetoProfile.prepare_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.NONE: 0>,\n",
       "  <ProfilerAction.RECORD_AND_SAVE: 3>): [<bound method _KinetoProfile.prepare_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.WARMUP: 1>,\n",
       "  <ProfilerAction.NONE: 0>): [functools.partial(<built-in function warn>, 'Incorrect schedule: WARMUP followed by NONE'), <bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.WARMUP: 1>, <ProfilerAction.WARMUP: 1>): [],\n",
       " (<ProfilerAction.WARMUP: 1>,\n",
       "  <ProfilerAction.RECORD: 2>): [<bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.WARMUP: 1>,\n",
       "  <ProfilerAction.RECORD_AND_SAVE: 3>): [<bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD: 2>,\n",
       "  <ProfilerAction.NONE: 0>): [functools.partial(<built-in function warn>, 'Incorrect schedule: RECORD followed by NONE'), <bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD: 2>,\n",
       "  <ProfilerAction.WARMUP: 1>): [functools.partial(<built-in function warn>, 'Incorrect schedule: RECORD followed by WARMUP'), <bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD: 2>, <ProfilerAction.RECORD: 2>): [],\n",
       " (<ProfilerAction.RECORD: 2>, <ProfilerAction.RECORD_AND_SAVE: 3>): [],\n",
       " (<ProfilerAction.RECORD_AND_SAVE: 3>,\n",
       "  <ProfilerAction.NONE: 0>): [<bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method profile._trace_ready of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD_AND_SAVE: 3>,\n",
       "  <ProfilerAction.WARMUP: 1>): [<bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method profile._trace_ready of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.prepare_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD_AND_SAVE: 3>,\n",
       "  <ProfilerAction.RECORD: 2>): [<bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method profile._trace_ready of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.prepare_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD_AND_SAVE: 3>,\n",
       "  <ProfilerAction.RECORD_AND_SAVE: 3>): [<bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method profile._trace_ready of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.prepare_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.WARMUP: 1>,\n",
       "  None): [<bound method _KinetoProfile.start_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD: 2>,\n",
       "  None): [<bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method profile._trace_ready of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>],\n",
       " (<ProfilerAction.RECORD_AND_SAVE: 3>,\n",
       "  None): [<bound method _KinetoProfile.stop_trace of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>, <bound method profile._trace_ready of <torch.profiler.profiler.profile object at 0x000002D93101DF60>>]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.events()[1] #буквально ивенты и их дети\n",
    "#id = 691715\n",
    "prof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bd3e72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment bs=16 thr=0.2 mode=quantile compose=two_layers\n",
      "After rank pruning left only 81 % of conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.0.conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer1.1.conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.1.conv2 layer params\n",
      "After rank pruning left only 81 % of layer2.0.conv1 layer params\n",
      "After rank pruning left only 81 % of layer2.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer2.0.downsample.0 layer params\n",
      "After rank pruning left only 81 % of layer2.1.conv1 layer params\n",
      "After rank pruning left only 81 % of layer2.1.conv2 layer params\n",
      "After rank pruning left only 80 % of layer3.0.conv1 layer params\n",
      "After rank pruning left only 80 % of layer3.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer3.0.downsample.0 layer params\n",
      "After rank pruning left only 80 % of layer3.1.conv1 layer params\n",
      "After rank pruning left only 80 % of layer3.1.conv2 layer params\n",
      "After rank pruning left only 80 % of layer4.0.conv1 layer params\n",
      "After rank pruning left only 80 % of layer4.0.conv2 layer params\n",
      "After rank pruning left only 80 % of layer4.0.downsample.0 layer params\n",
      "After rank pruning left only 80 % of layer4.1.conv1 layer params\n",
      "After rank pruning left only 80 % of layer4.1.conv2 layer params\n",
      "After rank pruning left only 80 % of fc layer params\n",
      "eval model_after\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 41.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment bs=16 thr=0.2 mode=quantile compose=two_layers\n",
      "After rank pruning left only 81 % of conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.0.conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer1.1.conv1 layer params\n",
      "After rank pruning left only 81 % of layer1.1.conv2 layer params\n",
      "After rank pruning left only 81 % of layer2.0.conv1 layer params\n",
      "After rank pruning left only 81 % of layer2.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer2.0.downsample.0 layer params\n",
      "After rank pruning left only 81 % of layer2.1.conv1 layer params\n",
      "After rank pruning left only 81 % of layer2.1.conv2 layer params\n",
      "After rank pruning left only 80 % of layer3.0.conv1 layer params\n",
      "After rank pruning left only 80 % of layer3.0.conv2 layer params\n",
      "After rank pruning left only 81 % of layer3.0.downsample.0 layer params\n",
      "After rank pruning left only 80 % of layer3.1.conv1 layer params\n",
      "After rank pruning left only 80 % of layer3.1.conv2 layer params\n",
      "After rank pruning left only 80 % of layer4.0.conv1 layer params\n",
      "After rank pruning left only 80 % of layer4.0.conv2 layer params\n",
      "After rank pruning left only 80 % of layer4.0.downsample.0 layer params\n",
      "After rank pruning left only 80 % of layer4.1.conv1 layer params\n",
      "After rank pruning left only 80 % of layer4.1.conv2 layer params\n",
      "After rank pruning left only 80 % of fc layer params\n",
      "eval model_before\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "throughput eval batches: 100%|██████████| 8/8 [00:00<00:00, 49.35batch/s]\n"
     ]
    }
   ],
   "source": [
    "#with_flops=True\n",
    "with profile(activities=[ProfilerActivity.CPU], \n",
    "             #with_stack=True, \n",
    "             record_shapes=True,\n",
    "             experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True),\n",
    "             ) as prof_after:\n",
    "    with record_function(\"model_inference\"):\n",
    "        ret_model_3, _ = experiment_body(TRAINED_LR, \n",
    "                                          bs=16, \n",
    "                                          thr=0.2,\n",
    "                                          mode=SLRStrategiesEnum._member_names_[0], \n",
    "                                          comp=\"two_layers\", \n",
    "                                          device_str=\"cpu\", \n",
    "                                          compare_with_decomposed=False, \n",
    "                                          n_eval=8,\n",
    "                                          eval_only_model_after=True)\n",
    "        \n",
    "#with_flops=True\n",
    "with profile(activities=[ProfilerActivity.CPU], \n",
    "             #with_stack=True, \n",
    "             record_shapes=True,\n",
    "             experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True),\n",
    "             ) as prof_before:\n",
    "    with record_function(\"model_inference\"):\n",
    "        ret_model_3, _ = experiment_body(TRAINED_LR, \n",
    "                                          bs=16, \n",
    "                                          thr=0.2,\n",
    "                                          mode=SLRStrategiesEnum._member_names_[0], \n",
    "                                          comp=\"two_layers\", \n",
    "                                          device_str=\"cpu\", \n",
    "                                          compare_with_decomposed=False, \n",
    "                                          n_eval=8,\n",
    "                                          eval_only_model_before=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a8547111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                        model_inference        42.36%     347.894ms       100.00%     821.242ms     821.242ms             1                                                                                []  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         6.05%      49.683ms         9.42%      77.351ms       7.735ms            10                                                                                []  \n",
      "                                         aten::quantile         0.95%       7.772ms         4.14%      33.978ms       5.663ms             6                                                            [[64], [], [], [], []]  \n",
      "                                           aten::matmul         0.00%      37.000us         2.73%      22.429ms       7.476ms             3                                                         [[412, 412], [412, 4608]]  \n",
      "                                               aten::mm         2.73%      22.389ms         2.73%      22.392ms       7.464ms             3                                                         [[412, 412], [412, 4608]]  \n",
      "                                            aten::clone         0.01%      59.000us         2.59%      21.282ms       3.547ms             6                                                            [[512, 512, 3, 3], []]  \n",
      "                                            aten::copy_         2.56%      21.059ms         2.56%      21.059ms       3.510ms             6                                          [[512, 512, 3, 3], [512, 512, 3, 3], []]  \n",
      "                                           aten::conv2d         0.16%       1.283ms         2.44%      20.079ms       2.510ms             8                              [[16, 3, 32, 32], [52, 3, 7, 7], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.13%       1.036ms         2.29%      18.796ms       2.349ms             8                      [[16, 3, 32, 32], [52, 3, 7, 7], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.04%     369.000us         2.16%      17.760ms       2.220ms             8      [[16, 3, 32, 32], [52, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         2.10%      17.251ms         2.12%      17.391ms       2.174ms             8                              [[16, 3, 32, 32], [52, 3, 7, 7], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.01%     120.000us         2.05%      16.856ms     702.333us            24                           [[16, 512, 1, 1], [412, 512, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.02%     171.000us         2.04%      16.736ms     697.333us            24                   [[16, 512, 1, 1], [412, 512, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.03%     272.000us         2.02%      16.565ms     690.208us            24   [[16, 512, 1, 1], [412, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         1.95%      15.987ms         1.98%      16.293ms     678.875us            24                           [[16, 512, 1, 1], [412, 512, 3, 3], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.01%     106.000us         1.86%      15.292ms     637.167us            24                           [[16, 256, 2, 2], [204, 256, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.03%     267.000us         1.85%      15.186ms     632.750us            24                   [[16, 256, 2, 2], [204, 256, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.06%     497.000us         1.82%      14.919ms     621.625us            24   [[16, 256, 2, 2], [204, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.02%     137.000us         1.79%      14.692ms     459.125us            32                              [[16, 64, 8, 8], [52, 64, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.02%     180.000us         1.77%      14.555ms     454.844us            32                      [[16, 64, 8, 8], [52, 64, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.04%     322.000us         1.75%      14.375ms     449.219us            32      [[16, 64, 8, 8], [52, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                           aten::matmul         0.07%     557.000us         1.63%      13.394ms      13.394ms             1                                                             [[52, 52], [52, 147]]  \n",
      "                                               aten::mm         1.56%      12.833ms         1.56%      12.837ms      12.837ms             1                                                             [[52, 52], [52, 147]]  \n",
      "                               aten::mkldnn_convolution         1.51%      12.394ms         1.51%      12.440ms     388.750us            32                              [[16, 64, 8, 8], [52, 64, 3, 3], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         1.38%      11.294ms         1.39%      11.381ms     474.208us            24                           [[16, 256, 2, 2], [204, 256, 3, 3], [], [], [], [], []]  \n",
      "                                       aten::max_pool2d         0.10%     842.000us         1.14%       9.390ms       1.174ms             8                                            [[16, 64, 16, 16], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.04%     315.000us         1.07%       8.827ms     367.792us            24                           [[16, 128, 4, 4], [104, 128, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.02%     179.000us         1.06%       8.741ms     364.208us            24                   [[16, 128, 4, 4], [104, 128, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.02%     189.000us         1.05%       8.628ms     269.625us            32                           [[16, 412, 1, 1], [512, 412, 1, 1], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%     171.000us         1.04%       8.562ms     356.750us            24   [[16, 128, 4, 4], [104, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                          aten::max_pool2d_with_indices         1.04%       8.548ms         1.04%       8.548ms       1.069ms             8                                            [[16, 64, 16, 16], [], [], [], [], []]  \n",
      "                                             aten::sort         0.65%       5.367ms         1.03%       8.444ms     703.667us            12                                                                    [[64], [], []]  \n",
      "                                      aten::convolution         0.03%     238.000us         1.03%       8.439ms     263.719us            32                   [[16, 412, 1, 1], [512, 412, 1, 1], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.04%     335.000us         1.00%       8.201ms     256.281us            32   [[16, 412, 1, 1], [512, 412, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                               aten::to         0.16%       1.337ms         0.96%       7.896ms      13.804us           572                                                              [[], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         0.93%       7.677ms         0.96%       7.866ms     245.812us            32                           [[16, 412, 1, 1], [512, 412, 1, 1], [], [], [], [], []]  \n",
      "                                            aten::clone         0.01%      44.000us         0.93%       7.619ms       1.270ms             6                                                            [[256, 256, 3, 3], []]  \n",
      "                                            aten::clone         0.47%       3.883ms         0.91%       7.506ms       3.753ms             2                                                               [[64, 3, 7, 7], []]  \n",
      "                                            aten::copy_         0.91%       7.450ms         0.91%       7.450ms       1.242ms             6                                          [[256, 256, 3, 3], [256, 256, 3, 3], []]  \n",
      "                               aten::mkldnn_convolution         0.90%       7.373ms         0.90%       7.418ms     309.083us            24                           [[16, 128, 4, 4], [104, 128, 3, 3], [], [], [], [], []]  \n",
      "                                              aten::div         0.50%       4.143ms         0.84%       6.876ms      42.975us           160                                                                 [[3, 32, 32], []]  \n",
      "                                               aten::ge         0.57%       4.694ms         0.84%       6.868ms     327.048us            21                                                                          [[], []]  \n",
      "                                         aten::_to_copy         0.64%       5.216ms         0.82%       6.714ms      17.171us           391                                                      [[], [], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.07%     592.000us         0.80%       6.536ms     204.250us            32                           [[16, 204, 2, 2], [256, 204, 1, 1], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.03%     226.000us         0.74%       6.041ms     188.781us            32                   [[16, 204, 2, 2], [256, 204, 1, 1], [], [], [], [], [], [], []]  \n",
      "                                           aten::matmul         0.00%      11.000us         0.73%       6.021ms       6.021ms             1                                                         [[412, 412], [412, 2304]]  \n",
      "                                               aten::mm         0.73%       6.009ms         0.73%       6.010ms       6.010ms             1                                                         [[412, 412], [412, 2304]]  \n",
      "                                           aten::conv2d         0.00%      38.000us         0.73%       5.962ms     745.250us             8                           [[16, 256, 2, 2], [412, 256, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.01%      57.000us         0.72%       5.924ms     740.500us             8                   [[16, 256, 2, 2], [412, 256, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.01%     117.000us         0.71%       5.867ms     733.375us             8   [[16, 256, 2, 2], [412, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.01%      48.000us         0.71%       5.855ms     731.875us             8                            [[16, 52, 16, 16], [64, 52, 1, 1], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.03%     280.000us         0.71%       5.815ms     181.719us            32   [[16, 204, 2, 2], [256, 204, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.01%      68.000us         0.71%       5.807ms     725.875us             8                    [[16, 52, 16, 16], [64, 52, 1, 1], [], [], [], [], [], [], []]  \n",
      "                                          aten::permute         0.64%       5.280ms         0.70%       5.757ms       1.151ms             5                                                              [[64, 64, 1, 1], []]  \n",
      "                                     aten::_convolution         0.01%      81.000us         0.70%       5.739ms     717.375us             8    [[16, 52, 16, 16], [64, 52, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                            aten::zeros         0.03%     241.000us         0.69%       5.683ms     270.619us            21                                                              [[], [], [], [], []]  \n",
      "                                           aten::matmul         0.00%      18.000us         0.68%       5.544ms       1.848ms             3                                                         [[104, 104], [104, 1152]]  \n",
      "                               aten::mkldnn_convolution         0.65%       5.353ms         0.67%       5.535ms     172.969us            32                           [[16, 204, 2, 2], [256, 204, 1, 1], [], [], [], [], []]  \n",
      "                                               aten::mm         0.67%       5.526ms         0.67%       5.526ms       1.842ms             3                                                         [[104, 104], [104, 1152]]  \n",
      "                                           aten::conv2d         0.11%     912.000us         0.66%       5.386ms     168.312us            32                           [[16, 104, 4, 4], [128, 104, 1, 1], [], [], [], [], []]  \n",
      "                                             aten::diag         0.01%      51.000us         0.63%       5.172ms       1.034ms             5                                                                       [[204], []]  \n",
      "                                       aten::diag_embed         0.02%     157.000us         0.62%       5.121ms       1.024ms             5                                                               [[204], [], [], []]  \n",
      "                                           aten::conv2d         0.01%     111.000us         0.61%       4.996ms     156.125us            32                              [[16, 52, 8, 8], [64, 52, 1, 1], [], [], [], [], []]  \n",
      "                                            aten::index         0.60%       4.951ms         0.60%       4.963ms       1.654ms             3                                                                 [[512, 4608], []]  \n",
      "                                      aten::convolution         0.09%     717.000us         0.59%       4.885ms     152.656us            32                      [[16, 52, 8, 8], [64, 52, 1, 1], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         0.59%       4.828ms         0.59%       4.875ms     609.375us             8                            [[16, 52, 16, 16], [64, 52, 1, 1], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         0.57%       4.645ms         0.57%       4.687ms     585.875us             8                           [[16, 256, 2, 2], [412, 256, 3, 3], [], [], [], [], []]  \n",
      "                                            aten::zero_         0.00%      31.000us         0.56%       4.620ms     924.000us             5                                                                      [[204, 204]]  \n",
      "                                            aten::fill_         0.56%       4.589ms         0.56%       4.589ms     917.800us             5                                                                  [[204, 204], []]  \n",
      "                                      aten::convolution         0.03%     242.000us         0.55%       4.527ms     141.469us            32                   [[16, 104, 4, 4], [128, 104, 1, 1], [], [], [], [], [], [], []]  \n",
      "                                            aten::clone         0.22%       1.820ms         0.54%       4.461ms      13.941us           320                                                                 [[3, 32, 32], []]  \n",
      "                                       aten::batch_norm         0.08%     644.000us         0.54%       4.427ms     553.375us             8                        [[16, 64, 16, 16], [64], [64], [64], [64], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%     196.000us         0.53%       4.385ms     137.031us            32   [[16, 104, 4, 4], [128, 104, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                               aten::eq         0.22%       1.780ms         0.53%       4.329ms      27.056us           160                                                                         [[1], []]  \n",
      "                               aten::mkldnn_convolution         0.50%       4.116ms         0.51%       4.189ms     130.906us            32                           [[16, 104, 4, 4], [128, 104, 1, 1], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%     200.000us         0.51%       4.168ms     130.250us            32      [[16, 52, 8, 8], [64, 52, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                       aten::batch_norm         0.04%     330.000us         0.51%       4.161ms     104.025us            40                     [[16, 512, 1, 1], [512], [512], [512], [512], [], [], [], []]  \n",
      "                                             aten::set_         0.50%       4.144ms         0.50%       4.144ms      17.267us           240                                                                         [[0], []]  \n",
      "                                            aten::clone         0.00%      33.000us         0.48%       3.973ms     794.600us             5                                                            [[256, 256, 1, 1], []]  \n",
      "                               aten::mkldnn_convolution         0.47%       3.893ms         0.48%       3.968ms     124.000us            32                              [[16, 52, 8, 8], [64, 52, 1, 1], [], [], [], [], []]  \n",
      "                                    aten::empty_strided         0.48%       3.936ms         0.48%       3.936ms       4.096us           961                                                          [[], [], [], [], [], []]  \n",
      "                                            aten::clone         0.00%      10.000us         0.47%       3.891ms       1.946ms             2                                                            [[512, 256, 3, 3], []]  \n",
      "                                            aten::copy_         0.47%       3.876ms         0.47%       3.876ms     775.200us             5                                          [[256, 256, 1, 1], [256, 256, 1, 1], []]  \n",
      "                           aten::_batch_norm_impl_index         0.05%     451.000us         0.47%       3.873ms      96.825us            40                     [[16, 512, 1, 1], [512], [512], [512], [512], [], [], [], []]  \n",
      "                                            aten::copy_         0.47%       3.859ms         0.47%       3.859ms       1.929ms             2                                          [[512, 256, 3, 3], [512, 256, 3, 3], []]  \n",
      "                                           aten::conv2d         0.01%      45.000us         0.47%       3.820ms     477.500us             8                           [[16, 128, 4, 4], [204, 128, 3, 3], [], [], [], [], []]  \n",
      "                                           aten::arange         0.21%       1.749ms         0.46%       3.784ms      90.095us            42                                                          [[], [], [], [], [], []]  \n",
      "                           aten::_batch_norm_impl_index         0.15%       1.219ms         0.46%       3.783ms     472.875us             8                        [[16, 64, 16, 16], [64], [64], [64], [64], [], [], [], []]  \n",
      "                                      aten::convolution         0.00%      34.000us         0.46%       3.775ms     471.875us             8                   [[16, 128, 4, 4], [204, 128, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.01%      72.000us         0.46%       3.741ms     467.625us             8   [[16, 128, 4, 4], [204, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                            aten::clone         0.01%      63.000us         0.45%       3.671ms     611.833us             6                                                            [[128, 128, 3, 3], []]  \n",
      "                                            aten::empty         0.43%       3.520ms         0.43%       3.520ms       1.478us          2381                                                          [[], [], [], [], [], []]  \n",
      "                                            aten::copy_         0.43%       3.512ms         0.43%       3.512ms     585.333us             6                                          [[128, 128, 3, 3], [128, 128, 3, 3], []]  \n",
      "                                aten::native_batch_norm         0.37%       3.066ms         0.41%       3.360ms      84.000us            40                         [[16, 512, 1, 1], [512], [512], [512], [512], [], [], []]  \n",
      "                                           aten::matmul         0.00%      17.000us         0.40%       3.309ms       1.103ms             3                                                         [[204, 204], [204, 2304]]  \n",
      "                                               aten::mm         0.40%       3.291ms         0.40%       3.292ms       1.097ms             3                                                         [[204, 204], [204, 2304]]  \n",
      "                                       aten::contiguous         0.04%     328.000us         0.40%       3.291ms      20.569us           160                                                                 [[3, 32, 32], []]  \n",
      "                               aten::mkldnn_convolution         0.39%       3.199ms         0.39%       3.203ms     400.375us             8                           [[16, 128, 4, 4], [204, 128, 3, 3], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.00%      31.000us         0.38%       3.083ms     385.375us             8                             [[16, 64, 8, 8], [104, 64, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.00%      34.000us         0.37%       3.052ms     381.500us             8                     [[16, 64, 8, 8], [104, 64, 3, 3], [], [], [], [], [], [], []]  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 821.242ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof_after.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0373d0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                                        model_inference        35.71%     117.082ms       100.00%     327.907ms     327.907ms             1                                                                                []  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        11.40%      37.386ms        17.27%      56.623ms       5.662ms            10                                                                                []  \n",
      "                                           aten::conv2d         0.04%     121.000us         5.86%      19.204ms     800.167us            24                           [[16, 512, 1, 1], [512, 512, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.06%     201.000us         5.82%      19.083ms     795.125us            24                   [[16, 512, 1, 1], [512, 512, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.08%     252.000us         5.76%      18.882ms     786.750us            24   [[16, 512, 1, 1], [512, 512, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         5.61%      18.388ms         5.68%      18.630ms     776.250us            24                           [[16, 512, 1, 1], [512, 512, 3, 3], [], [], [], [], []]  \n",
      "                                           aten::matmul         0.01%      26.000us         5.07%      16.615ms       5.538ms             3                                                         [[412, 412], [412, 4608]]  \n",
      "                                               aten::mm         5.06%      16.589ms         5.06%      16.589ms       5.530ms             3                                                         [[412, 412], [412, 4608]]  \n",
      "                                           aten::conv2d         0.05%     151.000us         3.43%      11.240ms     351.250us            32                              [[16, 64, 8, 8], [64, 64, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.06%     188.000us         3.38%      11.089ms     346.531us            32                      [[16, 64, 8, 8], [64, 64, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.08%     256.000us         3.32%      10.901ms     340.656us            32      [[16, 64, 8, 8], [64, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         3.21%      10.518ms         3.25%      10.645ms     332.656us            32                              [[16, 64, 8, 8], [64, 64, 3, 3], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.03%      94.000us         3.21%      10.523ms     438.458us            24                           [[16, 256, 2, 2], [256, 256, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.04%     118.000us         3.18%      10.429ms     434.542us            24                   [[16, 256, 2, 2], [256, 256, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.05%     160.000us         3.14%      10.311ms     429.625us            24   [[16, 256, 2, 2], [256, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         3.07%      10.051ms         3.10%      10.151ms     422.958us            24                           [[16, 256, 2, 2], [256, 256, 3, 3], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.03%     106.000us         2.46%       8.059ms     335.792us            24                           [[16, 128, 4, 4], [128, 128, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.04%     116.000us         2.43%       7.953ms     331.375us            24                   [[16, 128, 4, 4], [128, 128, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.05%     160.000us         2.39%       7.837ms     326.542us            24   [[16, 128, 4, 4], [128, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         2.32%       7.598ms         2.34%       7.677ms     319.875us            24                           [[16, 128, 4, 4], [128, 128, 3, 3], [], [], [], [], []]  \n",
      "                                       aten::max_pool2d         0.02%      52.000us         1.82%       5.964ms     745.500us             8                                            [[16, 64, 16, 16], [], [], [], [], []]  \n",
      "                          aten::max_pool2d_with_indices         1.80%       5.912ms         1.80%       5.912ms     739.000us             8                                            [[16, 64, 16, 16], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.02%      65.000us         1.57%       5.164ms     645.500us             8                              [[16, 3, 32, 32], [64, 3, 7, 7], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.03%      92.000us         1.56%       5.099ms     637.375us             8                      [[16, 3, 32, 32], [64, 3, 7, 7], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.04%     134.000us         1.53%       5.007ms     625.875us             8      [[16, 3, 32, 32], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         1.45%       4.770ms         1.49%       4.873ms     609.125us             8                              [[16, 3, 32, 32], [64, 3, 7, 7], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.01%      33.000us         1.38%       4.516ms     564.500us             8                           [[16, 256, 2, 2], [512, 256, 3, 3], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.01%      47.000us         1.37%       4.483ms     560.375us             8                   [[16, 256, 2, 2], [512, 256, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%      55.000us         1.35%       4.436ms     554.500us             8   [[16, 256, 2, 2], [512, 256, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         1.32%       4.320ms         1.34%       4.381ms     547.625us             8                           [[16, 256, 2, 2], [512, 256, 3, 3], [], [], [], [], []]  \n",
      "                                            aten::clone         0.65%       2.123ms         1.30%       4.259ms      13.309us           320                                                                 [[3, 32, 32], []]  \n",
      "                                            aten::index         1.26%       4.129ms         1.26%       4.132ms       1.377ms             3                                                                 [[512, 4608], []]  \n",
      "                                           aten::conv2d         0.01%      38.000us         1.03%       3.364ms     420.500us             8                             [[16, 64, 8, 8], [128, 64, 1, 1], [], [], [], [], []]  \n",
      "                                           aten::matmul         0.01%      17.000us         1.02%       3.349ms       1.116ms             3                                                         [[104, 104], [104, 1152]]  \n",
      "                                               aten::to         0.29%     965.000us         1.02%       3.336ms       5.832us           572                                                              [[], [], [], [], []]  \n",
      "                                               aten::mm         1.02%       3.332ms         1.02%       3.332ms       1.111ms             3                                                         [[104, 104], [104, 1152]]  \n",
      "                                      aten::convolution         0.02%      51.000us         1.01%       3.326ms     415.750us             8                     [[16, 64, 8, 8], [128, 64, 1, 1], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%      68.000us         1.00%       3.275ms     409.375us             8     [[16, 64, 8, 8], [128, 64, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                              aten::div         0.59%       1.941ms         0.99%       3.245ms      20.281us           160                                                                 [[3, 32, 32], []]  \n",
      "                               aten::mkldnn_convolution         0.96%       3.149ms         0.98%       3.207ms     400.875us             8                             [[16, 64, 8, 8], [128, 64, 1, 1], [], [], [], [], []]  \n",
      "                                            aten::clone         0.01%      21.000us         0.97%       3.188ms     531.333us             6                                                            [[512, 512, 3, 3], []]  \n",
      "                                            aten::copy_         0.92%       3.018ms         0.92%       3.018ms     503.000us             6                                          [[512, 512, 3, 3], [512, 512, 3, 3], []]  \n",
      "                                           aten::matmul         0.00%       2.000us         0.90%       2.935ms       2.935ms             1                                                         [[412, 412], [412, 2304]]  \n",
      "                                               aten::mm         0.89%       2.933ms         0.89%       2.933ms       2.933ms             1                                                         [[412, 412], [412, 2304]]  \n",
      "                                           aten::conv2d         0.02%      52.000us         0.88%       2.881ms     360.125us             8                           [[16, 256, 2, 2], [512, 256, 1, 1], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.02%      69.000us         0.86%       2.829ms     353.625us             8                   [[16, 256, 2, 2], [512, 256, 1, 1], [], [], [], [], [], [], []]  \n",
      "                                           aten::conv2d         0.09%     280.000us         0.85%       2.783ms     347.875us             8                           [[16, 128, 4, 4], [256, 128, 3, 3], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.03%      83.000us         0.84%       2.760ms     345.000us             8   [[16, 256, 2, 2], [512, 256, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.01%      41.000us         0.84%       2.754ms     344.250us             8                   [[16, 128, 4, 4], [256, 128, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%      52.000us         0.83%       2.713ms     339.125us             8   [[16, 128, 4, 4], [256, 128, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                       aten::contiguous         0.13%     425.000us         0.82%       2.694ms      16.837us           160                                                                 [[3, 32, 32], []]  \n",
      "                               aten::mkldnn_convolution         0.80%       2.607ms         0.82%       2.677ms     334.625us             8                           [[16, 256, 2, 2], [512, 256, 1, 1], [], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         0.79%       2.576ms         0.81%       2.661ms     332.625us             8                           [[16, 128, 4, 4], [256, 128, 3, 3], [], [], [], [], []]  \n",
      "                                           aten::matmul         0.00%       7.000us         0.78%       2.558ms     852.667us             3                                                         [[204, 204], [204, 2304]]  \n",
      "                                               aten::mm         0.78%       2.551ms         0.78%       2.551ms     850.333us             3                                                         [[204, 204], [204, 2304]]  \n",
      "                                           aten::conv2d         0.08%     256.000us         0.76%       2.502ms     312.750us             8                             [[16, 64, 8, 8], [128, 64, 3, 3], [], [], [], [], []]  \n",
      "                                         aten::_to_copy         0.56%       1.848ms         0.76%       2.488ms       6.363us           391                                                      [[], [], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.01%      39.000us         0.75%       2.471ms     308.875us             8                     [[16, 64, 8, 8], [128, 64, 3, 3], [], [], [], [], [], [], []]  \n",
      "                                               aten::to         0.21%     703.000us         0.75%       2.454ms      15.338us           160                                                     [[3, 32, 32], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%      52.000us         0.74%       2.432ms     304.000us             8     [[16, 64, 8, 8], [128, 64, 3, 3], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                       aten::batch_norm         0.04%     137.000us         0.74%       2.422ms      60.550us            40                     [[16, 512, 1, 1], [512], [512], [512], [512], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         0.72%       2.345ms         0.73%       2.380ms     297.500us             8                             [[16, 64, 8, 8], [128, 64, 3, 3], [], [], [], [], []]  \n",
      "                                         aten::quantile         0.20%     657.000us         0.72%       2.359ms     393.167us             6                                                            [[64], [], [], [], []]  \n",
      "                                               aten::eq         0.29%     964.000us         0.71%       2.312ms      14.450us           160                                                                         [[1], []]  \n",
      "                           aten::_batch_norm_impl_index         0.13%     422.000us         0.69%       2.258ms      56.450us            40                     [[16, 512, 1, 1], [512], [512], [512], [512], [], [], [], []]  \n",
      "                                           aten::conv2d         0.06%     184.000us         0.67%       2.209ms     276.125us             8                           [[16, 128, 4, 4], [256, 128, 1, 1], [], [], [], [], []]  \n",
      "                                         aten::_to_copy         0.42%       1.381ms         0.66%       2.180ms      13.625us           160                                             [[3, 32, 32], [], [], [], [], [], []]  \n",
      "                                      aten::convolution         0.01%      37.000us         0.66%       2.175ms     271.875us             8                   [[16, 128, 4, 4], [256, 128, 1, 1], [], [], [], [], [], [], []]  \n",
      "                                     aten::_convolution         0.02%      50.000us         0.65%       2.138ms     267.250us             8   [[16, 128, 4, 4], [256, 128, 1, 1], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                                       aten::batch_norm         0.03%      99.000us         0.64%       2.096ms      52.400us            40                     [[16, 256, 2, 2], [256], [256], [256], [256], [], [], [], []]  \n",
      "                               aten::mkldnn_convolution         0.63%       2.064ms         0.64%       2.088ms     261.000us             8                           [[16, 128, 4, 4], [256, 128, 1, 1], [], [], [], [], []]  \n",
      "                           aten::_batch_norm_impl_index         0.09%     284.000us         0.60%       1.982ms      49.550us            40                     [[16, 256, 2, 2], [256], [256], [256], [256], [], [], [], []]  \n",
      "                                aten::native_batch_norm         0.48%       1.575ms         0.56%       1.821ms      45.525us            40                         [[16, 512, 1, 1], [512], [512], [512], [512], [], [], []]  \n",
      "                                              aten::any         0.40%       1.297ms         0.55%       1.803ms      11.269us           160                                                                             [[1]]  \n",
      "                                       aten::batch_norm         0.04%     129.000us         0.54%       1.781ms      44.525us            40                     [[16, 128, 4, 4], [128], [128], [128], [128], [], [], [], []]  \n",
      "                                            aten::copy_         0.54%       1.770ms         0.54%       1.770ms       3.688us           480                                                    [[3, 32, 32], [3, 32, 32], []]  \n",
      "                                aten::native_batch_norm         0.45%       1.486ms         0.53%       1.732ms      43.300us            40                         [[16, 256, 2, 2], [256], [256], [256], [256], [], [], []]  \n",
      "                                         aten::quantile         0.09%     299.000us         0.51%       1.671ms     334.200us             5                                                           [[128], [], [], [], []]  \n",
      "                           aten::_batch_norm_impl_index         0.08%     262.000us         0.51%       1.657ms      41.425us            40                     [[16, 128, 4, 4], [128], [128], [128], [128], [], [], [], []]  \n",
      "                                    aten::empty_strided         0.50%       1.645ms         0.50%       1.645ms       1.712us           961                                                          [[], [], [], [], [], []]  \n",
      "                                            aten::index         0.47%       1.552ms         0.47%       1.555ms     518.333us             3                                                                 [[256, 2304], []]  \n",
      "                                            aten::empty         0.47%       1.528ms         0.47%       1.528ms       0.683us          2237                                                          [[], [], [], [], [], []]  \n",
      "                                       aten::batch_norm         0.04%     124.000us         0.45%       1.490ms      46.562us            32                          [[16, 64, 8, 8], [64], [64], [64], [64], [], [], [], []]  \n",
      "                                aten::native_batch_norm         0.37%       1.226ms         0.43%       1.399ms      34.975us            40                         [[16, 128, 4, 4], [128], [128], [128], [128], [], [], []]  \n",
      "                           aten::_batch_norm_impl_index         0.14%     473.000us         0.42%       1.366ms      42.688us            32                          [[16, 64, 8, 8], [64], [64], [64], [64], [], [], [], []]  \n",
      "                                         aten::quantile         0.06%     208.000us         0.37%       1.212ms     303.000us             4                                                           [[512], [], [], [], []]  \n",
      "                                            aten::clone         0.01%      17.000us         0.37%       1.210ms     201.667us             6                                                            [[256, 256, 3, 3], []]  \n",
      "                                            aten::relu_         0.06%     181.000us         0.34%       1.131ms      35.344us            32                                                                  [[16, 64, 8, 8]]  \n",
      "                                            aten::copy_         0.34%       1.130ms         0.34%       1.130ms     188.333us             6                                          [[256, 256, 3, 3], [256, 256, 3, 3], []]  \n",
      "                                            aten::relu_         0.07%     244.000us         0.33%       1.087ms      33.969us            32                                                                 [[16, 128, 4, 4]]  \n",
      "                              aten::adaptive_avg_pool2d         0.05%     164.000us         0.32%       1.060ms     132.500us             8                                                             [[16, 512, 1, 1], []]  \n",
      "                                         aten::quantile         0.06%     210.000us         0.31%       1.028ms     205.600us             5                                                           [[256], [], [], [], []]  \n",
      "                                       aten::clamp_min_         0.30%     979.000us         0.30%     979.000us      30.594us            32                                                              [[16, 64, 8, 8], []]  \n",
      "                                            aten::clone         0.01%      31.000us         0.29%     946.000us     157.667us             6                                                            [[128, 128, 3, 3], []]  \n",
      "                                       aten::empty_like         0.22%     727.000us         0.28%     929.000us       5.806us           160                                                 [[3, 32, 32], [], [], [], [], []]  \n",
      "                                       aten::clamp_min_         0.28%     928.000us         0.28%     928.000us      29.000us            32                                                             [[16, 128, 4, 4], []]  \n",
      "                                            aten::index         0.27%     900.000us         0.28%     905.000us     226.250us             4                                                                  [[512, 512], []]  \n",
      "                                            aten::copy_         0.27%     900.000us         0.27%     900.000us     150.000us             6                                          [[128, 128, 3, 3], [128, 128, 3, 3], []]  \n",
      "                                          aten::permute         0.24%     793.000us         0.27%     898.000us       5.612us           160                                                                 [[32, 32, 3], []]  \n",
      "                                             aten::mean         0.04%     133.000us         0.27%     896.000us     112.000us             8                                                     [[16, 512, 1, 1], [], [], []]  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 327.907ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof_before.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989b48dd",
   "metadata": {},
   "source": [
    "#time total = avg * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c0604a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::conv2d 541.0 [[16, 3, 32, 32], [52, 3, 7, 7], [], [], [], [], []]\n",
      "aten::conv2d 322.5 [[16, 52, 16, 16], [64, 52, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 364.59375 [[16, 64, 8, 8], [52, 64, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 146.71875 [[16, 52, 8, 8], [64, 52, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 311.5 [[16, 64, 8, 8], [104, 64, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 137.65625 [[16, 104, 4, 4], [128, 104, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 349.8333333333333 [[16, 128, 4, 4], [104, 128, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 123.5 [[16, 64, 8, 8], [52, 64, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 121.875 [[16, 52, 4, 4], [128, 52, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 425.375 [[16, 128, 4, 4], [204, 128, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 162.96875 [[16, 204, 2, 2], [256, 204, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 546.125 [[16, 256, 2, 2], [204, 256, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 145.5 [[16, 128, 4, 4], [104, 128, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 173.125 [[16, 104, 2, 2], [256, 104, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 673.625 [[16, 256, 2, 2], [412, 256, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 232.28125 [[16, 412, 1, 1], [512, 412, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 578.8333333333334 [[16, 512, 1, 1], [412, 512, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 151.375 [[16, 256, 2, 2], [204, 256, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 188.5 [[16, 204, 1, 1], [512, 204, 1, 1], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "conv2d_info_after = []\n",
    "for element in prof_after.key_averages(group_by_input_shape=True):\n",
    "    if (element.key == \"aten::conv2d\"):\n",
    "        print(element.key, element.cpu_time, element.input_shapes)\n",
    "        conv2d_info_after.append((element.key, element.cpu_time, np.cumprod(element.input_shapes[1])[-1]))\n",
    "#кажется идут по порядку, значит можем сравнить каждую пару с одним модулем из before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0122f8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conv2d_info_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529f1941",
   "metadata": {},
   "source": [
    "#пример с input [16, 256, 2, 2] и conv_w = [204, 256, 1, 1]\n",
    "\n",
    "256 фичей по 2x2   \n",
    "умножаются на свёртки которые съедают 256 фичей и 1x1 каждая, при этом их 204  \n",
    "применений свёртки (H - h) * (W - w), где HW исход изобр, hw - размер свёртки (если не учит pad и strat)  \n",
    "при применении свёртки происходит h * w операций\n",
    "и такая свёртка применяется в глубину на in_shape\n",
    "Итого: in_shape * (h * w) * (~H * W) операций на 1 3д свёртку  \n",
    "А их ещё out_shape, поэтому всего in_shape * out_shape * (h * w) * (~H * W)  \n",
    "а думал что просто in_shape * h * w * out_shape  \n",
    "Т. е. свёртка ещё и зависит от удобства внутреннего разбиения. От удобства того, какой\n",
    "после первого полуслоя придёт тензор. Хотя на самом деле член (H * W) можно и не учитывать, как я вижу он остаётся неизменным, меняются in и out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "aec42fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::conv2d 506.625 [[16, 3, 32, 32], [64, 3, 7, 7], [], [], [], [], []]\n",
      "aten::conv2d 392.65625 [[16, 64, 8, 8], [64, 64, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 317.5 [[16, 64, 8, 8], [128, 64, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 353.8333333333333 [[16, 128, 4, 4], [128, 128, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 278.625 [[16, 64, 8, 8], [128, 64, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 344.25 [[16, 128, 4, 4], [256, 128, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 445.1666666666667 [[16, 256, 2, 2], [256, 256, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 257.0 [[16, 128, 4, 4], [256, 128, 1, 1], [], [], [], [], []]\n",
      "aten::conv2d 496.25 [[16, 256, 2, 2], [512, 256, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 778.375 [[16, 512, 1, 1], [512, 512, 3, 3], [], [], [], [], []]\n",
      "aten::conv2d 263.125 [[16, 256, 2, 2], [512, 256, 1, 1], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "conv2d_info_before = []\n",
    "for element in prof_before.key_averages(group_by_input_shape=True):\n",
    "    if (element.key == \"aten::conv2d\"):\n",
    "        print(element.key, element.cpu_time, element.input_shapes)\n",
    "        conv2d_info_before.append((element.key, element.cpu_time, np.cumprod(element.input_shapes[1])[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d4030d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(conv2d_info_before).shape\n",
    "#22 так как 11 сгруппированных на 2 (latency и throughput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf23e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512x256x1x1 conv 1.2889733840304183\n",
      "old 131072 new 52224 + 104448 = 156672\n",
      "512x512x3x3 conv 1.0411311053984575\n",
      "old 2359296 new 1898496 + 210944 = 2109440\n",
      "64x3 (first) conv 1.725296442687747\n",
      "old 9408 new 7644 + 3328 = 10972\n",
      "64x64 (second) conv 1.3010204081632653\n",
      "old 36864 new 29952 + 3328 = 33280\n"
     ]
    }
   ],
   "source": [
    "print(\"512x256x1x1 conv\", (151 + 188) / 263) #логично что первый член меньше, так как 204x256 меньше 512x204\n",
    "print(\"old 131072 new 52224 + 104448 = 156672\")\n",
    "\n",
    "print(\"512x512x3x3 conv\", (578 + 232) / 778) #412x512x3x3 and 512x412x1x1 - в сумме членов меньше, но сумма параметров больше\n",
    "print(\"old 2359296 new 1898496 + 210944 = 2109440\")\n",
    "\n",
    "print(\"64x3 (first) conv\", (541 + 332) / 506)\n",
    "print(\"old 9408 new 7644 + 3328 = 10972\")\n",
    "\n",
    "print(\"64x64 (second) conv\", (364 + 146) / 392) #52x64x3x3 and 64x52x1x1\n",
    "print(\"old 36864 new 29952 + 3328 = 33280\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d65521",
   "metadata": {},
   "source": [
    "В общем на процессоре я бы поставил под вопрос, из за того ли, что у нас какие-то overheadы есть, или из-за того, что просто становится два умножения.\n",
    "Из оверхедов я вижу только gap между свёртками, но обычно он не превышает 50ns. Однако это лишь\n",
    "примерно от 1/5 до 1/16.\n",
    "\n",
    "Если на gpu обнаружится ещё больший gap на расходы - ответ будет однозначным за переписывание. Если нет - то тут скорее дело кроется в природе разложенных матриц.\n",
    "\n",
    "Проверить на 0.5 - там не давало результатов тоже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298a4bd",
   "metadata": {},
   "source": [
    "В целом видно, что действительно время увеличивается больше для маленьких свёрток, так как время на её разложении падает не сильно (по сравнению с добавкой от второго слагаемого).\n",
    "\n",
    "Плюс не забываем про gap постоянный примерно в 50ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d72f8410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old torch.Size([64, 3, 7, 7])\n",
      "new Vh torch.Size([52, 3, 7, 7])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 9408 new 7644 + 3328 = 10972\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "\n",
      "---\n",
      "old torch.Size([64, 64, 3, 3])\n",
      "new Vh torch.Size([52, 64, 3, 3])\n",
      "new U torch.Size([64, 52, 1, 1])\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "\n",
      "---\n",
      "old torch.Size([128, 64, 3, 3])\n",
      "new Vh torch.Size([104, 64, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 73728 new 59904 + 13312 = 73216\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([104, 128, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 147456 new 119808 + 13312 = 133120\n",
      "\n",
      "---\n",
      "old torch.Size([128, 64, 1, 1])\n",
      "new Vh torch.Size([52, 64, 1, 1])\n",
      "new U torch.Size([128, 52, 1, 1])\n",
      "old 8192 new 3328 + 6656 = 9984\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([104, 128, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 147456 new 119808 + 13312 = 133120\n",
      "\n",
      "---\n",
      "old torch.Size([128, 128, 3, 3])\n",
      "new Vh torch.Size([104, 128, 3, 3])\n",
      "new U torch.Size([128, 104, 1, 1])\n",
      "old 147456 new 119808 + 13312 = 133120\n",
      "\n",
      "---\n",
      "old torch.Size([256, 128, 3, 3])\n",
      "new Vh torch.Size([204, 128, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 294912 new 235008 + 52224 = 287232\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([204, 256, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 589824 new 470016 + 52224 = 522240\n",
      "\n",
      "---\n",
      "old torch.Size([256, 128, 1, 1])\n",
      "new Vh torch.Size([104, 128, 1, 1])\n",
      "new U torch.Size([256, 104, 1, 1])\n",
      "old 32768 new 13312 + 26624 = 39936\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([204, 256, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 589824 new 470016 + 52224 = 522240\n",
      "\n",
      "---\n",
      "old torch.Size([256, 256, 3, 3])\n",
      "new Vh torch.Size([204, 256, 3, 3])\n",
      "new U torch.Size([256, 204, 1, 1])\n",
      "old 589824 new 470016 + 52224 = 522240\n",
      "\n",
      "---\n",
      "old torch.Size([512, 256, 3, 3])\n",
      "new Vh torch.Size([412, 256, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 1179648 new 949248 + 210944 = 1160192\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([412, 512, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 2359296 new 1898496 + 210944 = 2109440\n",
      "\n",
      "---\n",
      "old torch.Size([512, 256, 1, 1])\n",
      "new Vh torch.Size([204, 256, 1, 1])\n",
      "new U torch.Size([512, 204, 1, 1])\n",
      "old 131072 new 52224 + 104448 = 156672\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([412, 512, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 2359296 new 1898496 + 210944 = 2109440\n",
      "\n",
      "---\n",
      "old torch.Size([512, 512, 3, 3])\n",
      "new Vh torch.Size([412, 512, 3, 3])\n",
      "new U torch.Size([512, 412, 1, 1])\n",
      "old 2359296 new 1898496 + 210944 = 2109440\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "compare_module_shapes(ret_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d7279b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) 0\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 1\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 2\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 3\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 4\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 5\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 6\n",
      "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) 7\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 8\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 9\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 10\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 11\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) 12\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 13\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 14\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 15\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 16\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) 17\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 18\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 19\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, child in ret_model_3.model_before.named_modules():\n",
    "    if (isinstance(child, nn.Conv2d)):\n",
    "        print(child, i)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_compare_conv2d = pd.DataFrame()\n",
    "# df_compare_conv2d[\"before_time\"] = np.array(conv2d_info_before)[:, 1]\n",
    "# df_compare_conv2d[\"before_params\"] = np.array(conv2d_info_before)[:, 2]\n",
    "\n",
    "\n",
    "\n",
    "# merged_conv2d_after = []\n",
    "# for i in range(0, len(conv2d_info_after) - 1, 2): #почему то не хватило пары\n",
    "#     sum_time = conv2d_info_after[i][1] + conv2d_info_after[i+1][1]\n",
    "#     sum_params = conv2d_info_after[i][2] + conv2d_info_after[i+1][2]\n",
    "#     merged_conv2d_after.append((sum_time, sum_params))\n",
    "\n",
    "# df_compare_conv2d[\"after_time\"] = np.array(merged_conv2d_after)[:, 0]\n",
    "# df_compare_conv2d[\"after_params\"] = np.array(merged_conv2d_after)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d2f77176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operations = pd.DataFrame()\n",
    "df_operations[\"times\"] = np.array(conv2d_info_after + conv2d_info_before)[:, 1]\n",
    "df_operations[\"params\"] = np.array(conv2d_info_after + conv2d_info_before)[:, 2]\n",
    "df_operations[\"params\"] = pd.to_numeric(df_operations[\"params\"], errors=\"coerce\")\n",
    "df_operations[\"times\"] = pd.to_numeric(df_operations[\"times\"], errors=\"coerce\")\n",
    "df_operations = df_operations.sort_values(by=[\"params\"],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732d204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2d9d339ceb0>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.xticks(np.arange(1, 3000000, 100000))\n",
    "plt.title(\"Average conv2d time vs param count\")\n",
    "plt.xlabel(\"Params count\")\n",
    "plt.ylabel(\"Time, us\")\n",
    "plt.plot(df_operations[\"params\"], df_operations[\"times\"])\n",
    "plt.scatter(df_operations[\"params\"], df_operations[\"times\"])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.xticks(np.arange(1, 3000000, 100000))\n",
    "# plt.xscale('log')\n",
    "# plt.plot(df_operations[\"params\"], df_operations[\"times\"])\n",
    "# plt.scatter(df_operations[\"params\"], df_operations[\"times\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b1cfd0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old 9408 new 7644 + 3328 = 10972\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "old 36864 new 29952 + 3328 = 33280\n",
      "old 73728 new 59904 + 13312 = 73216\n",
      "old 147456 new 119808 + 13312 = 133120\n",
      "old 8192 new 3328 + 6656 = 9984\n",
      "old 147456 new 119808 + 13312 = 133120\n",
      "old 147456 new 119808 + 13312 = 133120\n",
      "old 294912 new 235008 + 52224 = 287232\n",
      "old 589824 new 470016 + 52224 = 522240\n",
      "old 32768 new 13312 + 26624 = 39936\n",
      "old 589824 new 470016 + 52224 = 522240\n",
      "old 589824 new 470016 + 52224 = 522240\n",
      "old 1179648 new 949248 + 210944 = 1160192\n",
      "old 2359296 new 1898496 + 210944 = 2109440\n",
      "old 131072 new 52224 + 104448 = 156672\n",
      "old 2359296 new 1898496 + 210944 = 2109440\n",
      "old 2359296 new 1898496 + 210944 = 2109440\n"
     ]
    }
   ],
   "source": [
    "def compare_module_shapes_2(lowRankModel):\n",
    "    new_modules = list(lowRankModel.model_after.named_modules())\n",
    "    for i, (name, module) in enumerate(lowRankModel.model_before.named_modules()):\n",
    "        if isinstance(module, torch.nn.Conv2d): \n",
    "            # print(\"old\", module.weight.shape)\n",
    "            # print(\"new Vh\", new_modules[i][1].Vh.shape)\n",
    "            # print(\"new U\", new_modules[i][1].U.shape)\n",
    "            print(\"old\", count_params(module), \"new\", new_modules[i][1].Vh.numel(), \"+\", new_modules[i][1].U.numel(), \"=\", count_params(new_modules[i][1]))\n",
    "\n",
    "compare_module_shapes_2(ret_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b2bf29f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11181642\n",
      "10179510\n"
     ]
    }
   ],
   "source": [
    "print(count_params(ret_model_3.model_before))\n",
    "print(count_params(ret_model_3.model_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff416388",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_after.export_chrome_trace(\"prof_after_two_layer_thr_02.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c71984",
   "metadata": {},
   "source": [
    "#сравнить теперь для CUDA и посмотреть как идут операции."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
