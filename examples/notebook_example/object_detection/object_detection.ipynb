{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaefsky\\Python\\Fedcore\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torchvision.datasets\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.ops import nms\n",
    "from torchmetrics.detection import MeanAveragePrecision as MAP\n",
    "from PIL import ImageDraw\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights,\\\n",
    "    fasterrcnn_mobilenet_v3_large_fpn, FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
    "from torchvision.models.detection.retinanet import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights\n",
    "\n",
    "from fedot.core.pipelines.pipeline_builder import PipelineBuilder\n",
    "\n",
    "from fedcore.tools.ruler import PerformanceEvaluatorOD\n",
    "from fedcore.architecture.dataset.object_detection_datasets import YOLODataset, COCODataset, UnlabeledDataset\n",
    "from fedcore.architecture.comptutaional.devices import default_device\n",
    "from fedcore.architecture.utils.loader import collate\n",
    "from fedcore.data.data import CompressionInputData\n",
    "from fedcore.inference.onnx import ONNXInferenceModel\n",
    "from fedcore.neural_compressor.config import Torch2ONNXConfig\n",
    "from fedcore.repository.constanst_repository import FEDOT_TASK\n",
    "from fedcore.repository.initializer_industrial_models import FedcoreModels\n",
    "from fedcore.repository.constanst_repository import CROSS_ENTROPY, MSE\n",
    "from fedcore.architecture.visualisation.visualization import plot_train_test_loss_metric, apply_nms, get_image, filter_boxes\n",
    "from fedcore.architecture.utils.loader import get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = default_device()\n",
    "IMG_SIZE = 512\n",
    "NMS_THRESH = 0.5\n",
    "THRESH = 0.5\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "INIT_LR = 4e-5\n",
    "\n",
    "EPS = 10\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "DATASET_NAME = 'dataset-5000'\n",
    "OUTPUT_PATH = f'datasets/{DATASET_NAME}/output/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:12:24,323 - Initialising experiment setup\n",
      "Data Path:  c:\\Users\\Kaefsky\\Python\\Fedcore\\FedCore\\datasets\\dataset-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting:   0%|          | 0/4201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-08 15:12:24,473 - Initialising Industrial Repository\n",
      "2024-07-08 15:12:25,136 - Initialising solver\n",
      "[{'boxes': tensor([[478.0000, 147.0003, 509.0003, 177.0001],\n",
      "        [480.0000, 254.9997, 511.0003, 283.9998],\n",
      "        [127.0003, 255.9999, 156.0000, 282.9997],\n",
      "        [130.0000, 438.9999, 158.9997, 468.0000],\n",
      "        [128.0000, 331.9999, 156.9997, 359.9999],\n",
      "        [506.0003, 291.9998, 536.0003, 322.9998],\n",
      "        [480.0003, 331.9999, 510.0003, 359.9999],\n",
      "        [101.9997, 293.9999, 131.9997, 321.9998],\n",
      "        [129.0000, 147.0001, 159.0000, 176.0002],\n",
      "        [476.0000, 452.0002, 507.0003, 470.0001],\n",
      "        [314.0003, 337.9999, 385.0000, 367.0000]], device='cuda:0'), 'labels': tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4], device='cuda:0')}]\n",
      "2024-07-08 15:12:26,971 - AssumptionsHandler - Memory consumption for fitting of the initial pipeline in main session: current 2.3 MiB, max: 178.2 MiB\n",
      "2024-07-08 15:12:26,973 - ApiComposer - Initial pipeline was fitted in 1.8 sec.\n",
      "2024-07-08 15:12:26,975 - AssumptionsHandler - Preset was changed to best_quality due to fit time estimation for initial model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting:   0%|          | 0/4201 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'dict_keys' object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m fedcore_compressor \u001B[38;5;241m=\u001B[39m FedCore(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mexperiment_setup)\n\u001B[0;32m      8\u001B[0m input_data \u001B[38;5;241m=\u001B[39m YOLODataset(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatasets/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mDATASET_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, dataset_name\u001B[38;5;241m=\u001B[39mDATASET_NAME, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, log\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mfedcore_compressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m pruned_model \u001B[38;5;241m=\u001B[39m fedcore_compressor\u001B[38;5;241m.\u001B[39mpredict(input_data)\u001B[38;5;241m.\u001B[39mpredict\n\u001B[0;32m     11\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mc:\\Users\\Kaefsky\\Python\\Fedcore\\FedCore\\fedcore\\api\\main.py:148\u001B[0m, in \u001B[0;36mFedCore.fit\u001B[1;34m(self, input_data, **kwargs)\u001B[0m\n\u001B[0;32m    146\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_data \u001B[38;5;241m=\u001B[39m input_preproc\u001B[38;5;241m.\u001B[39mcheck_input_data()\n\u001B[0;32m    147\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__init_solver()\n\u001B[1;32m--> 148\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_data \u001B[38;5;241m=\u001B[39m deepcopy(input_data)  \u001B[38;5;66;03m# we do not want to make inplace changes\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\Kaefsky\\Python\\Fedcore\\.venv\\lib\\site-packages\\fedot\\api\\main.py:176\u001B[0m, in \u001B[0;36mFedot.fit\u001B[1;34m(self, features, target, predefined_model)\u001B[0m\n\u001B[0;32m    172\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_pipeline \u001B[38;5;241m=\u001B[39m PredefinedModel(predefined_model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog,\n\u001B[0;32m    173\u001B[0m                                             use_input_preprocessing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\n\u001B[0;32m    174\u001B[0m                                                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124muse_input_preprocessing\u001B[39m\u001B[38;5;124m'\u001B[39m))\u001B[38;5;241m.\u001B[39mfit()\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 176\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_pipeline, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_models, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhistory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_composer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobtain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_pipeline \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    179\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNo models were found\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mc:\\Users\\Kaefsky\\Python\\Fedcore\\.venv\\lib\\site-packages\\fedot\\api\\api_utils\\api_composer.py:66\u001B[0m, in \u001B[0;36mApiComposer.obtain_model\u001B[1;34m(self, train_data)\u001B[0m\n\u001B[0;32m     63\u001B[0m initial_assumption, fitted_assumption \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropose_and_fit_initial_assumption(train_data)\n\u001B[0;32m     65\u001B[0m multi_objective \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetrics) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 66\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit_params_for_composing\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimedelta_composing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_objective\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mmessage(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoML configured.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     69\u001B[0m                  \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Parameters tuning: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwith_tuning\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     70\u001B[0m                  \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Time limit: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtimeout\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m min.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     71\u001B[0m                  \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Set of candidate models: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mavailable_operations\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     73\u001B[0m best_pipeline, best_pipeline_candidates, gp_composer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompose_pipeline(\n\u001B[0;32m     74\u001B[0m     train_data,\n\u001B[0;32m     75\u001B[0m     initial_assumption,\n\u001B[0;32m     76\u001B[0m     fitted_assumption\n\u001B[0;32m     77\u001B[0m )\n",
      "File \u001B[1;32mc:\\Users\\Kaefsky\\Python\\Fedcore\\.venv\\lib\\site-packages\\fedot\\api\\api_utils\\params.py:114\u001B[0m, in \u001B[0;36mApiParams.init_params_for_composing\u001B[1;34m(self, datetime_composing, multi_objective)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minit_params_for_composing\u001B[39m(\u001B[38;5;28mself\u001B[39m, datetime_composing: Optional[datetime\u001B[38;5;241m.\u001B[39mtimedelta], multi_objective: \u001B[38;5;28mbool\u001B[39m):\n\u001B[0;32m    112\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Method to initialize ``PipelineComposerRequirements``, ``GPAlgorithmParameters``,\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m    ``GraphGenerationParams``\"\"\"\u001B[39;00m\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit_composer_requirements\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatetime_composing\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_optimizer_params(multi_objective\u001B[38;5;241m=\u001B[39mmulti_objective)\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_graph_generation_params(requirements\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomposer_requirements)\n",
      "File \u001B[1;32mc:\\Users\\Kaefsky\\Python\\Fedcore\\.venv\\lib\\site-packages\\fedot\\api\\api_utils\\params.py:132\u001B[0m, in \u001B[0;36mApiParams.init_composer_requirements\u001B[1;34m(self, datetime_composing)\u001B[0m\n\u001B[0;32m    128\u001B[0m primary_operations, secondary_operations \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m    129\u001B[0m     PipelineOperationRepository\u001B[38;5;241m.\u001B[39mdivide_operations(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mavailable_operations\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask)\n\u001B[0;32m    131\u001B[0m composer_requirements_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_params_repository\u001B[38;5;241m.\u001B[39mget_params_for_composer_requirements(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata)\n\u001B[1;32m--> 132\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomposer_requirements \u001B[38;5;241m=\u001B[39m PipelineComposerRequirements(primary\u001B[38;5;241m=\u001B[39mprimary_operations,\n\u001B[0;32m    133\u001B[0m                                                           secondary\u001B[38;5;241m=\u001B[39msecondary_operations,\n\u001B[0;32m    134\u001B[0m                                                           timeout\u001B[38;5;241m=\u001B[39mdatetime_composing,\n\u001B[0;32m    135\u001B[0m                                                           n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcomposer_requirements_params)\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomposer_requirements\n",
      "File \u001B[1;32m<string>:24\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m(self, num_of_generations, timeout, early_stopping_iterations, early_stopping_timeout, keep_n_best, max_graph_fit_time, n_jobs, show_progress, collect_intermediate_metric, parallelization_mode, static_individual_metadata, keep_history, history_dir, agent_dir, start_depth, max_depth, min_arity, max_arity, primary, secondary, cv_folds)\u001B[0m\n",
      "File \u001B[1;32mc:\\Users\\Kaefsky\\Python\\Fedcore\\.venv\\lib\\site-packages\\fedot\\core\\pipelines\\pipeline_composer_requirements.py:24\u001B[0m, in \u001B[0;36mPipelineComposerRequirements.__post_init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__post_init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__post_init__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv_folds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv_folds \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     26\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of folds for KFold cross validation must be 2 or more.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mc:\\Users\\Kaefsky\\Python\\Fedcore\\.venv\\lib\\site-packages\\golem\\core\\optimisers\\optimization_parameters.py:92\u001B[0m, in \u001B[0;36mGraphRequirements.__post_init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__post_init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;66;03m# check and convert n_jobs to non-negative\u001B[39;00m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs \u001B[38;5;241m=\u001B[39m determine_n_jobs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n\u001B[1;32m---> 92\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m field_name, field_value \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdataclasses\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masdict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     93\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(field_value, Number) \u001B[38;5;129;01mand\u001B[39;00m field_value \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     94\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValue of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfield_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be non-negative\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\dataclasses.py:1238\u001B[0m, in \u001B[0;36masdict\u001B[1;34m(obj, dict_factory)\u001B[0m\n\u001B[0;32m   1236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_dataclass_instance(obj):\n\u001B[0;32m   1237\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masdict() should be called on dataclass instances\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_asdict_inner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_factory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\dataclasses.py:1245\u001B[0m, in \u001B[0;36m_asdict_inner\u001B[1;34m(obj, dict_factory)\u001B[0m\n\u001B[0;32m   1243\u001B[0m result \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   1244\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fields(obj):\n\u001B[1;32m-> 1245\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[43m_asdict_inner\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_factory\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1246\u001B[0m     result\u001B[38;5;241m.\u001B[39mappend((f\u001B[38;5;241m.\u001B[39mname, value))\n\u001B[0;32m   1247\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dict_factory(result)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\dataclasses.py:1279\u001B[0m, in \u001B[0;36m_asdict_inner\u001B[1;34m(obj, dict_factory)\u001B[0m\n\u001B[0;32m   1275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(obj)((_asdict_inner(k, dict_factory),\n\u001B[0;32m   1276\u001B[0m                       _asdict_inner(v, dict_factory))\n\u001B[0;32m   1277\u001B[0m                      \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m obj\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m   1278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1279\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\copy.py:161\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    159\u001B[0m reductor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__reduce_ex__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reductor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 161\u001B[0m     rv \u001B[38;5;241m=\u001B[39m \u001B[43mreductor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    163\u001B[0m     reductor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__reduce__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot pickle 'dict_keys' object"
     ]
    }
   ],
   "source": [
    "from fedcore.api.main import FedCore\n",
    "\n",
    "experiment_setup = {'problem': 'detection',\n",
    "                    'use_input_preprocessing': False}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fedcore_compressor = FedCore(**experiment_setup)\n",
    "    input_data = YOLODataset(path=f'datasets/{DATASET_NAME}', dataset_name=DATASET_NAME, train=True, log=True)\n",
    "    fedcore_compressor.fit(input_data)\n",
    "    pruned_model = fedcore_compressor.predict(input_data).predict\n",
    "    _ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 479, 640])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path:  c:\\Users\\Kaefsky\\Python\\Fedcore\\FedCore\\datasets\\dataset-5000\n"
     ]
    }
   ],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    # v2.Normalize(mean=MEAN, std=STD),\n",
    "    # v2.Resize((IMG_SIZE, IMG_SIZE))\n",
    "])\n",
    "\n",
    "tr_dataset = YOLODataset(path=f'datasets/{DATASET_NAME}', dataset_name=DATASET_NAME, train=True, log=True)\n",
    "    \n",
    "# train_dataset = COCODataset(images_path=COCO_PATH + \"train2017/\",\n",
    "#                             json_path=COCO_PATH + \"annotations/instances_train2017.json\",\n",
    "#                             transform=transform)\n",
    "\n",
    "test_dataset = YOLODataset(path=f'datasets/{DATASET_NAME}', dataset_name=DATASET_NAME, train=False)\n",
    "# val_dataset = COCODataset(images_path=COCO_PATH + \"val2017/\",\n",
    "#                             json_path=COCO_PATH + \"annotations/instances_val2017.json\",\n",
    "#                             transform=transform)\n",
    "val_dataset = UnlabeledDataset(images_path=f'datasets/{DATASET_NAME}/val/images/')\n",
    "\n",
    "\n",
    "tr_loader = get_loader(tr_dataset, batch_size=BATCH_SIZE, train=True)\n",
    "test_loader = get_loader(test_dataset)\n",
    "val_loader = get_loader(val_dataset)\n",
    "\n",
    "# More accurate, very slow to train\n",
    "# model = fasterrcnn_resnet50_fpn_v2()\n",
    "\n",
    "# Less accurate, but faster to train\n",
    "model = fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "\n",
    "# test\n",
    "# model = ssdlite320_mobilenet_v3_large(weights=SSDLite320_MobileNet_V3_Large_Weights.DEFAULT)\n",
    "# model = retinanet_resnet50_fpn_v2()\n",
    "\n",
    "num_classes = len(tr_dataset.classes)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes).to(device)\n",
    "model.to(device)\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=INIT_LR, momentum=0.9, weight_decay=INIT_LR/2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1051 [00:03<04:52,  3.55it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_loss = np.zeros(EPS)\n",
    "test_loss = np.zeros(EPS)\n",
    "tr_map = np.zeros(EPS)\n",
    "test_map = np.zeros(EPS)\n",
    "tr_time = np.zeros(EPS)\n",
    "\n",
    "for ep in range(EPS):       \n",
    "    tStart = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    loss_arr = np.zeros(len(tr_loader))\n",
    "    desc='Training'\n",
    "    for i, (images, targets) in enumerate(tqdm(tr_loader, desc=desc)):\n",
    "        # forward\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        loss_arr[i] = loss\n",
    "        # backward + optimize\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()           \n",
    "    tr_loss[ep] = loss_arr.mean()\n",
    "    \n",
    "    # Calculate train mAP\n",
    "    model.eval()\n",
    "    evaluator = PerformanceEvaluatorOD(model, tr_loader, batch_size=BATCH_SIZE)\n",
    "    target_metric = evaluator.measure_target_metric()\n",
    "    tr_map[ep] = float(target_metric[\"map\"])\n",
    "            \n",
    "    # Evaluate the model\n",
    "    model.train()\n",
    "    loss_arr = np.zeros(len(test_loader)) \n",
    "    desc='Evaluating'\n",
    "    for i, (images, targets) in enumerate(tqdm(test_loader, desc=desc)):\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        loss_arr[i] = loss\n",
    "    test_loss[ep] = loss_arr.mean()\n",
    "    \n",
    "    # Calculate test mAP\n",
    "    model.eval()\n",
    "    evaluator = PerformanceEvaluatorOD(model, test_loader, batch_size=1)\n",
    "    target_metric = evaluator.measure_target_metric()\n",
    "    test_map[ep] = float(target_metric[\"map\"])\n",
    "    \n",
    "    # Optimize learning rate\n",
    "    scheduler.step(test_map[ep])\n",
    "    \n",
    "    tEnd = time.time()\n",
    "    tr_time[ep] = float(tEnd - tStart)\n",
    "    \n",
    "    # Print metrics\n",
    "    p = int(math.log(ep + 1, 10))\n",
    "    print('-' * (40 + p))\n",
    "    print('| %d | TRAIN | Loss: %.3f | mAP: %.3f |' %\n",
    "            (ep + 1, tr_loss[ep], tr_map[ep]))\n",
    "    print('| %d | TEST  | Loss: %.3f | mAP: %.3f |' %\n",
    "            (ep + 1, test_loss[ep], test_map[ep]))\n",
    "    print('-' * (13 + p), \n",
    "            'Time: %.2f' % tr_time[ep], \n",
    "            '-' * 14)\n",
    "    \n",
    "    # Saving best model\n",
    "    if test_map[ep].max():\n",
    "        best_model = model\n",
    "    \n",
    "    # Most crucial step\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Early stop\n",
    "    if ep > 4 and test_map[ep] <= test_map[ep - 4]:\n",
    "        tr_loss = tr_loss[:ep + 1]\n",
    "        test_loss = test_loss[:ep + 1]\n",
    "        tr_map = tr_map[:ep + 1]\n",
    "        test_map = test_map[:ep + 1]\n",
    "        train_time = tr_time[:ep + 1]\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "# Final evaluating\n",
    "model = best_model\n",
    "evaluator = PerformanceEvaluatorOD(model, test_loader, batch_size=1)\n",
    "performance = evaluator.eval()\n",
    "print('Before quantization')\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_train_test_loss_metric(tr_loss, test_loss, tr_map, test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "now = str(datetime.datetime.now())[2:-16]\n",
    "torch.save(model, f'{model._get_name()}_{DATASET_NAME}_{now}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('FasterRCNN_african-wildlife_24-07-07.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "id = random.randint(0, len(val_dataset) - 1) # random or int\n",
    "test_data = test_loader.dataset[id]\n",
    "img, target = test_data\n",
    "input = torch.unsqueeze(img, dim=0)\n",
    "pred = model(input)\n",
    "pred = apply_nms(pred[0], NMS_THRESH)\n",
    "pred = filter_boxes(pred, THRESH)\n",
    "\n",
    "# Show inference image\n",
    "transform = v2.ToPILImage()\n",
    "img = transform(img)\n",
    "inference_img = get_image(img, pred, train_dataset.classes, target)\n",
    "inference_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting all inference images\n",
    "for data in val_loader:\n",
    "    image = data[0][0].cpu()\n",
    "    name = data[1][0]['name']\n",
    "    input = torch.unsqueeze(image, dim=0)\n",
    "    pred = model(input)\n",
    "    pred = apply_nms(pred[0], NMS_THRESH)\n",
    "    pred = filter_boxes(pred, THRESH)\n",
    "    transform = v2.ToPILImage()\n",
    "    img = transform(image)\n",
    "    inference_img = get_image(img, pred, train_dataset.classes)\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "    inference_img.save(OUTPUT_PATH + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "repo = FedcoreModels().setup_repository()\n",
    "compression_pipeline = PipelineBuilder().add_node('post_training_quant').build()\n",
    "\n",
    "input_data = CompressionInputData(features=np.zeros((2, 2)),\n",
    "                                    idx=None,\n",
    "                                    calib_dataloader=val_loader,\n",
    "                                    task=FEDOT_TASK['regression'],\n",
    "                                    data_type=None,\n",
    "                                    target=model\n",
    ")\n",
    "\n",
    "input_data.supplementary_data.is_auto_preprocessed = True\n",
    "compression_pipeline.fit(input_data)\n",
    "quant_model = compression_pipeline.predict(input_data).predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "int8_onnx_config = Torch2ONNXConfig(\n",
    "    dtype=\"int8\",\n",
    "    opset_version=18,\n",
    "    quant_format=\"QDQ\",  # or \"QLinear\"\n",
    "    example_inputs=torch.unsqueeze(train_dataset[0][0], dim=0),\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "            'input' : {0 : 'batch_size'},\n",
    "            'output' : {0 : 'batch_size'}\n",
    "        }\n",
    ")\n",
    "\n",
    "quant_model.export(\"int8-model.onnx\", int8_onnx_config)\n",
    "onnx_model = ONNXInferenceModel(\"int8-model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = PerformanceEvaluatorOD(model, test_loader, batch_size=1)\n",
    "performance = evaluator.eval()\n",
    "print('after quantization')\n",
    "print(performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}