# Pyboost integration with Fedcore

1. Файл bechmark_eval.py
   2. Содержит класс ExperimentPipeline содержит 2 вида моделей GradientBoosting и FedcoreBoosting
   3. GradientBoosting - реализация из классического Pyboost. Там ключевое внимание для нас метод _fit(). FedcoreBoosting наследуется от GradientBoosting
   4. В нем нас интересуют строки 208-214 в них происходит построение нового дерева в ансамбле с использованием градиента и гессиана из предыдущего дерева
   5. В методе build_tree() нам нужны строчки 543-544 которые выполняют "проекцию" матриц градиента и гессиана с помощью различных методов рандомизации
   6. Список реализованных в Pyboost методов содержится в fedcore/repository/data/custom/boosting_config.py
   7. Список реализованных в Fecore методов содержится в fedcore/repository/data/custom/randomization_config.py
   8. Датасеты для бенчмарка берутся из fedcore/data/custom/load_data.py. Используется репозиторий UCIREPO, по умолчанию датасет - yeast.
2. Какие есть проблемы? На мой взгляд их 3 основных.
   1. "Аппроксимация" матриц градиента и гессиана выполняется для КАЖДОГО дерева - это довольно "жесткий" подход к аппроксимации. Нет ничего похожего на "scheduler" для аппроксимации (снижение размерности раз в N эпох) 
   2. Нет интеграции с методами эффективного "семплирования" исходного датасета (создание наиболее эффективной обучающей подвыборки).
   3. Сами методы "рандомизации" требуют обновления и расширения (обобщение на тензорный случай/подбор наиболее эффективной матрицы аппроксимации)
3. Какие улучшения напрашиваются?
   1. Начать стоит с того что бы переопредилить метод _fit() добавив в него реализованный нами callback который будет накапливать "историю" градиентов и гессианов которая потом будет использоваться для вычисления нового "низкорангового" градиента и гессиана
   2. Важно помнить - в ходе аппроксимации гессиана и градиента с помощью тензорных разложений мы можем получить разные ранги для каждого из них
   3. Надо добавить "техническую обвязку" - рассчет метрик для датасета, скорости инференса, логгирование параметров эксперимента.
   4. Надо реализовать класс который выполнял бы "семплирование" из исходного датасета на основе различных рандомизированных методов (потом можно добавить на основе "геометрических" подходов)

