2025-10-29 15:05:42,589 - __main__ - INFO - Loading model from HuggingFace: arnir0/Tiny-LLM
2025-10-29 15:05:43,211 - __main__ - INFO - Model loaded: LlamaForCausalLM
2025-10-29 15:05:43,573 - __main__ - INFO - Tokenizer loaded. Vocabulary size: 32000
2025-10-29 15:05:43,573 - __main__ - INFO - Generated fedcore_id: fedcore_d3b9c43e
2025-10-29 15:05:50,587 - __main__ - INFO - Dataset loaded: 1000 samples
2025-10-29 15:05:50,593 - __main__ - INFO - Dataset filtered: 647 samples
2025-10-29 15:05:50,611 - __main__ - INFO - Datasets split: train=517, val=64, test=66
2025-10-29 15:05:50,613 - __main__ - INFO - Example batch shape: torch.Size([4, 64])
2025-10-29 15:05:57,103 - __main__ - INFO - Trained model registered with ID: model_127967054714704
2025-10-29 15:05:57,104 - __main__ - INFO - Using fedcore_id: fedcore_d3b9c43e
2025-10-29 15:05:58,705 - __main__ - INFO - Using fedcore_id: fedcore_d3b9c43e
2025-10-29 15:05:59,181 - __main__ - INFO - Memory after cleanup: 0.1147 GB
2025-10-29 15:05:59,181 - __main__ - INFO - FINAL STATISTICS
2025-10-29 15:05:59,181 - __main__ - INFO - Training time:     6.17 sec
2025-10-29 15:05:59,181 - __main__ - INFO - Report time:       1.60 sec
2025-10-29 15:05:59,181 - __main__ - INFO - Total time:        15.79 sec
2025-10-29 15:05:59,181 - __main__ - INFO - MEMORY STATISTICS:
2025-10-29 15:05:59,182 - __main__ - INFO - Initial GPU memory:     0.0000 GB
2025-10-29 15:05:59,182 - __main__ - INFO - After training:          0.1642 GB
2025-10-29 15:05:59,182 - __main__ - INFO - After report:            0.1637 GB
2025-10-29 15:05:59,182 - __main__ - INFO - Final GPU memory:        0.1147 GB
2025-10-29 15:05:59,182 - __main__ - INFO - Peak memory:             0.1642 GB
2025-10-29 15:05:59,182 - __main__ - INFO - Memory freed:             0.0495 GB
2025-10-29 15:05:59,182 - __main__ - INFO - Cleanup efficiency:      30.1%
